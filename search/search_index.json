{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A collection of GPU-accelerated parallel game simulators for reinforcement learning (RL)</p> <p>[!NOTE]  \u2b50 If you find this project helpful, we would be grateful for your support through a GitHub star to help us grow the community and motivate further development!</p>"},{"location":"#why-pgx","title":"Why Pgx?","text":"<p>Brax, a JAX-native physics engine, provides extremely high-speed parallel simulation for RL in continuous state space. Then, what about RL in discrete state spaces like Chess, Shogi, and Go? Pgx provides a wide variety of JAX-native game simulators! Highlighted features include:</p> <ul> <li>\u26a1 Super fast in parallel execution on accelerators</li> <li>\ud83c\udfb2 Various game support including Backgammon, Chess, Shogi, and Go</li> <li>\ud83d\uddbc\ufe0f Beautiful visualization in SVG format</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":"<ul> <li>Getting started</li> <li>Pgx baseline models</li> <li>Export to PettingZoo API</li> </ul> <p>Read the Full Documentation for more details</p>"},{"location":"#training-examples","title":"Training examples","text":"<ul> <li>AlphaZero</li> <li>PPO</li> </ul>"},{"location":"#usage","title":"Usage","text":"<p>Pgx is available on PyPI. Note that your Python environment has <code>jax</code> and <code>jaxlib</code> installed, depending on your hardware specification.</p> <pre><code>$ pip install pgx\n</code></pre> <p>The following code snippet shows a simple example of using Pgx. You can try it out in this Colab. Note that all <code>step</code> functions in Pgx environments are JAX-native., i.e., they are all JIT-able. Please refer to the documentation for more details.</p> <pre><code>import jax\nimport pgx\n\nenv = pgx.make(\"go_19x19\")\ninit = jax.jit(jax.vmap(env.init))\nstep = jax.jit(jax.vmap(env.step))\n\nbatch_size = 1024\nkeys = jax.random.split(jax.random.PRNGKey(42), batch_size)\nstate = init(keys)  # vectorized states\nwhile not (state.terminated | state.truncated).all():\n    action = model(state.current_player, state.observation, state.legal_action_mask)\n    # step(state, action, keys) for stochastic envs\n    state = step(state, action)  # state.rewards with shape (1024, 2)\n</code></pre> <p>Pgx is a library that focuses on faster implementations rather than just the API itself.  However, the API itself is also sufficiently general. For example, all environments in Pgx can be converted to the AEC API of PettingZoo, and you can run Pgx environments through the PettingZoo API. You can see the demonstration in this Colab.</p> \ud83d\udce3 API v2 (v2.0.0)  Pgx has been updated from API **v1** to **v2** as of November 8, 2023 (release **`v2.0.0`**). As a result, the signature for `Env.step` has changed as follows:  - **v1**: `step(state: State, action: Array)` - **v2**: `step(state: State, action: Array, key: Optional[PRNGKey] = None)`  Also, `pgx.experimental.auto_reset` are changed to specify `key` as the third argument.  **Purpose of the update:** In API v1, even in environments with stochastic state transitions, the state transitions were deterministic, determined by the `_rng_key` inside the `state`. This was intentional, with the aim of increasing reproducibility. However, when using planning algorithms in this environment, there is a risk that information about the underlying true randomness could \"leak.\" To make it easier for users to conduct correct experiments, `Env.step` has been changed to explicitly specify a key.  **Impact of the update**: Since the `key` is optional, it is still possible to execute as `env.step(state, action)` like API v1 in deterministic environments like Go and chess, so there is no impact on these games. As of `v2.0.0`, **only 2048, backgammon, and MinAtar suite are affected by this change.**"},{"location":"#supported-games","title":"Supported games","text":"Backgammon Chess Shogi Go <p>Use <code>pgx.available_envs() -&gt; Tuple[EnvId]</code> to see the list of currently available games. Given an <code>&lt;EnvId&gt;</code>, you can create the environment via</p> <pre><code>&gt;&gt;&gt; env = pgx.make(&lt;EnvId&gt;)\n</code></pre> Game/EnvId Visualization Version Five-word description by ChatGPT 2048 <code>\"2048\"</code> <code>v2</code> Merge tiles to create 2048. Animal Shogi<code>\"animal_shogi\"</code> <code>v2</code> Animal-themed child-friendly shogi. Backgammon<code>\"backgammon\"</code> <code>v2</code> Luck aids bearing off checkers. Bridge bidding<code>\"bridge_bidding\"</code> <code>v1</code> Partners exchange information via bids. Chess<code>\"chess\"</code> <code>v2</code> Checkmate opponent's king to win. Connect Four<code>\"connect_four\"</code> <code>v0</code> Connect discs, win with four. Gardner Chess<code>\"gardner_chess\"</code> <code>v0</code> 5x5 chess variant, excluding castling. Go<code>\"go_9x9\"</code> <code>\"go_19x19\"</code> <code>v1</code> Strategically place stones, claim territory. Hex<code>\"hex\"</code> <code>v0</code> Connect opposite sides, block opponent. Kuhn Poker<code>\"kuhn_poker\"</code> <code>v1</code> Three-card betting and bluffing game. Leduc hold'em<code>\"leduc_holdem\"</code> <code>v0</code> Two-suit, limited deck poker. MinAtar/Asterix<code>\"minatar-asterix\"</code> <code>v1</code> Avoid enemies, collect treasure, survive. MinAtar/Breakout<code>\"minatar-breakout\"</code> <code>v1</code> Paddle, ball, bricks, bounce, clear. MinAtar/Freeway<code>\"minatar-freeway\"</code> <code>v1</code> Dodging cars, climbing up freeway. MinAtar/Seaquest<code>\"minatar-seaquest\"</code> <code>v1</code> Underwater submarine rescue and combat. MinAtar/SpaceInvaders<code>\"minatar-space_invaders\"</code> <code>v1</code> Alien shooter game, dodge bullets. Othello<code>\"othello\"</code> <code>v0</code> Flip and conquer opponent's pieces. Shogi<code>\"shogi\"</code> <code>v0</code> Japanese chess with captured pieces. Sparrow Mahjong<code>\"sparrow_mahjong\"</code> <code>v1</code> A simplified, children-friendly Mahjong. Tic-tac-toe<code>\"tic_tac_toe\"</code> <code>v0</code> Three in a row wins. Versioning policy  Each environment is versioned, and the version is incremented when there are changes that affect the performance of agents or when there are changes that are not backward compatible with the API. If you want to pursue complete reproducibility, we recommend that you check the version of Pgx and each environment as follows:  <pre><code>&gt;&gt;&gt; pgx.__version__\n'1.0.0'\n&gt;&gt;&gt; env.version\n'v0'\n</code></pre>"},{"location":"#see-also","title":"See also","text":"<p>Pgx is intended to complement these JAX-native environments with (classic) board game suits:</p> <ul> <li>RobertTLange/gymnax: JAX implementation of popular RL environments (classic control, bsuite, MinAtar, etc) and meta RL tasks</li> <li>google/brax: Rigidbody physics simulation in JAX and continuous-space RL tasks (ant, fetch, humanoid, etc)</li> <li>instadeepai/jumanji: A suite of diverse and challenging     RL environments in JAX (bin-packing, routing problems, etc)</li> <li>flairox/jaxmarl: Multi-Agent RL environments in JAX (simplified StarCraft, etc)</li> <li>corl-team/xland-minigrid: Meta-RL gridworld environments in JAX inspired by MiniGrid and XLand</li> <li>MichaelTMatthews/Craftax: (Crafter + NetHack) in JAX for open-ended RL</li> <li>epignatelli/navix: Re-implementation of MiniGrid in JAX</li> </ul> <p>Combining Pgx with these JAX-native algorithms/implementations might be an interesting direction:</p> <ul> <li>Anakin framework: Highly efficient RL framework that works with JAX-native environments on TPUs</li> <li>deepmind/mctx: JAX-native MCTS implementations, including AlphaZero and MuZero</li> <li>deepmind/rlax: JAX-native RL components</li> <li>google/evojax: Hardware-Accelerated neuroevolution</li> <li>RobertTLange/evosax: JAX-native evolution strategy (ES) implementations</li> <li>adaptive-intelligent-robotics/QDax: JAX-native Quality-Diversity (QD) algorithms</li> <li>luchris429/purejaxrl: Jax-native RL implementations</li> </ul>"},{"location":"#limitation","title":"Limitation","text":"<p>Currently, some environments, including Go and chess, do not perform well on TPUs. Please use GPUs instead.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use Pgx in your work, please cite our paper:</p> <pre><code>@inproceedings{koyamada2023pgx,\n  title={Pgx: Hardware-Accelerated Parallel Game Simulators for Reinforcement Learning},\n  author={Koyamada, Sotetsu and Okano, Shinri and Nishimori, Soichiro and Murata, Yu and Habara, Keigo and Kita, Haruka and Ishii, Shin},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={45716--45743},\n  volume={36},\n  year={2023}\n}\n</code></pre>"},{"location":"#license","title":"LICENSE","text":"<p>Apache-2.0</p>"},{"location":"animal_shogi/","title":"AnimalShogi","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"animal_shogi/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"animal_shogi\")\n</code></pre> <p>or you can directly load <code>AnimalShogi</code> class</p> <pre><code>from pgx.animal_shogi import AnimalShogi\n\nenv = AnimalShogi()\n</code></pre>"},{"location":"animal_shogi/#description","title":"Description","text":"<p>Animal Shogi (D\u014dbutsu sh\u014dgi) is a variant of shogi primarily developed for children. It consists of a 3x4 board and four types of pieces (five including promoted pieces). One of the rule differences from regular shogi is the Try Rule, where entering the opponent's territory with the king leads to victory.</p> <p>See also Wikipedia</p>"},{"location":"animal_shogi/#specs","title":"Specs","text":"Name Value Version <code>v2</code> Number of players <code>2</code> Number of actions <code>132</code> Observation shape <code>(4, 3, 194)</code> Observation type <code>float</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"animal_shogi/#observation","title":"Observation","text":"Index Description <code>[:, :, 0:5]</code> my pieces on board <code>[:, :, 5:10]</code> opponent's pieces on board <code>[:, :, 10:16]</code> my hands <code>[:, :, 16:22]</code> opponent's hands <code>[:, :, 22:24]</code> repetitions ... ... <code>[:, :, 193]</code> <code>player_id</code>'s turn' <code>[:, :, 194]</code> Elapsed timesteps (normalized to <code>1</code>)"},{"location":"animal_shogi/#action","title":"Action","text":"<p>Uses AlphaZero like action label:</p> <ul> <li><code>132</code> labels</li> <li>Move: <code>8 x 12</code> (direction) x (source square)</li> <li>Drop: <code>3 x 12</code> (drop piece type) x (destination square)</li> </ul>"},{"location":"animal_shogi/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"animal_shogi/#termination","title":"Termination","text":"<p>Termination happens when </p> <ol> <li>If either player's king is checkmated, or</li> <li>if either king enters the opponent's territory (farthest rank)</li> <li>If the same position occurs three times.</li> <li>If 250 moves have passed (a unique rule in Pgx).</li> </ol> <p>In cases 3 and 4, the game is declared a draw.</p>"},{"location":"animal_shogi/#version-history","title":"Version History","text":"<ul> <li><code>v2</code> : Fixed a bug in Pawn drop #1218 by @KazukiOhta (v2.3.0)</li> <li><code>v1</code> : Fixed visualization #1208 and bug in Gold's move #1209 by @KazukiOhta (v2.2.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"animal_shogi/#baseline-models","title":"Baseline models","text":"<p>Pgx offers a baseline model for Animal Shogi. Users can use it for an anchor opponent in evaluation. See our paper for more details. See this colab for how to use it.</p> <p>[!WARNING] Curren latest model (<code>animal_shogi_v0</code>) is trained with <code>v0</code> environment. It may perform significantly worse in <code>v1</code> environment.</p> Model ID Description <code>animal_shogi_v0</code> See our paper for the training details."},{"location":"api/","title":"Pgx API","text":"<p>This is the list of all public APIs of Pgx. Two important components in Pgx are <code>State</code> and <code>Env</code>.</p> <p>Naming convention of <code>EnvId</code></p> <p>Hyphen <code>-</code> is used to represent that there is a different original game source (e.g., <code>MinAtar</code>), and underscore <code>-</code> is used for the other cases.</p>"},{"location":"api/#pgx.State","title":"<code>pgx.State</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base state class of all Pgx game environments. Basically an immutable (frozen) dataclass. A basic usage is generating via <code>Env.init</code>:</p> <pre><code>state = env.init(jax.random.PRNGKey(0))\n</code></pre> <p>and <code>Env.step</code> receives and returns this state class:</p> <pre><code>state = env.step(state, action)\n</code></pre> <p>Serialization via <code>flax.struct.serialization</code> is supported. There are 6 common attributes over all games:</p> <p>Attributes:</p> Name Type Description <code>current_player</code> <code>Array</code> <p>id of agent to play. Note that this does NOT represent the turn (e.g., black/white in Go). This ID is consistent over the parallel vmapped states.</p> <code>observation</code> <code>Array</code> <p>observation for the current state. <code>Env.observe</code> is called to compute.</p> <code>rewards</code> <code>Array</code> <p>the <code>i</code>-th element indicates the intermediate reward for the agent with player-id <code>i</code>. If <code>Env.step</code> is called for a terminal state, the following <code>state.rewards</code> is zero for all players.</p> <code>terminated</code> <code>Array</code> <p>denotes that the state is terminal state. Note that some environments (e.g., Go) have an <code>max_termination_steps</code> parameter inside and will terminate within a limited number of states (following AlphaGo).</p> <code>truncated</code> <code>Array</code> <p>indicates that the episode ends with the reason other than termination. Note that current Pgx environments do not invoke truncation but users can use <code>TimeLimit</code> wrapper to truncate the environment. In Pgx environments, some MinAtar games may not terminate within a finite timestep. However, the other environments are supposed to terminate within a finite timestep with probability one.</p> <code>legal_action_mask</code> <code>Array</code> <p>Boolean array of legal actions. If illegal action is taken, the game will terminate immediately with the penalty to the palyer.</p> Source code in <code>pgx/core.py</code> <pre><code>@dataclass\nclass State(abc.ABC):\n    \"\"\"Base state class of all Pgx game environments. Basically an immutable (frozen) dataclass.\n    A basic usage is generating via `Env.init`:\n\n        state = env.init(jax.random.PRNGKey(0))\n\n    and `Env.step` receives and returns this state class:\n\n        state = env.step(state, action)\n\n    Serialization via `flax.struct.serialization` is supported.\n    There are 6 common attributes over all games:\n\n    Attributes:\n        current_player (Array): id of agent to play.\n            Note that this does NOT represent the turn (e.g., black/white in Go).\n            This ID is consistent over the parallel vmapped states.\n        observation (Array): observation for the current state.\n            `Env.observe` is called to compute.\n        rewards (Array): the `i`-th element indicates the intermediate reward for\n            the agent with player-id `i`. If `Env.step` is called for a terminal state,\n            the following `state.rewards` is zero for all players.\n        terminated (Array): denotes that the state is terminal state. Note that\n            some environments (e.g., Go) have an `max_termination_steps` parameter inside\n            and will terminate within a limited number of states (following AlphaGo).\n        truncated (Array): indicates that the episode ends with the reason other than termination.\n            Note that current Pgx environments do not invoke truncation but users can use `TimeLimit` wrapper\n            to truncate the environment. In Pgx environments, some MinAtar games may not terminate within a finite timestep.\n            However, the other environments are supposed to terminate within a finite timestep with probability one.\n        legal_action_mask (Array): Boolean array of legal actions. If illegal action is taken,\n            the game will terminate immediately with the penalty to the palyer.\n    \"\"\"\n\n    current_player: Array\n    observation: Array\n    rewards: Array\n    terminated: Array\n    truncated: Array\n    legal_action_mask: Array\n    _step_count: Array\n\n    @property\n    @abc.abstractmethod\n    def env_id(self) -&gt; EnvId:\n        \"\"\"Environment id (e.g. \"go_19x19\")\"\"\"\n        ...\n\n    def _repr_html_(self) -&gt; str:\n        return self.to_svg()\n\n    def to_svg(\n        self,\n        *,\n        color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n        scale: Optional[float] = None,\n    ) -&gt; str:\n        \"\"\"Return SVG string. Useful for visualization in notebook.\n\n        Args:\n            color_theme (Optional[Literal[\"light\", \"dark\"]]): xxx see also global config.\n            scale (Optional[float]): change image size. Default(None) is 1.0\n\n        Returns:\n            str: SVG string\n        \"\"\"\n        from pgx._src.visualizer import Visualizer\n\n        v = Visualizer(color_theme=color_theme, scale=scale)\n        return v.get_dwg(states=self).tostring()\n\n    def save_svg(\n        self,\n        filename,\n        *,\n        color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n        scale: Optional[float] = None,\n    ) -&gt; None:\n        \"\"\"Save the entire state (not observation) to a file.\n        The filename must end with `.svg`\n\n        Args:\n            color_theme (Optional[Literal[\"light\", \"dark\"]]): xxx see also global config.\n            scale (Optional[float]): change image size. Default(None) is 1.0\n\n        Returns:\n            None\n        \"\"\"\n        from pgx._src.visualizer import save_svg\n\n        save_svg(self, filename, color_theme=color_theme, scale=scale)\n</code></pre>"},{"location":"api/#pgx.State.env_id","title":"<code>env_id</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Environment id (e.g. \"go_19x19\")</p>"},{"location":"api/#pgx.State.save_svg","title":"<code>save_svg(filename, *, color_theme=None, scale=None)</code>","text":"<p>Save the entire state (not observation) to a file. The filename must end with <code>.svg</code></p> <p>Parameters:</p> Name Type Description Default <code>color_theme</code> <code>Optional[Literal['light', 'dark']]</code> <p>xxx see also global config.</p> <code>None</code> <code>scale</code> <code>Optional[float]</code> <p>change image size. Default(None) is 1.0</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>pgx/core.py</code> <pre><code>def save_svg(\n    self,\n    filename,\n    *,\n    color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n    scale: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Save the entire state (not observation) to a file.\n    The filename must end with `.svg`\n\n    Args:\n        color_theme (Optional[Literal[\"light\", \"dark\"]]): xxx see also global config.\n        scale (Optional[float]): change image size. Default(None) is 1.0\n\n    Returns:\n        None\n    \"\"\"\n    from pgx._src.visualizer import save_svg\n\n    save_svg(self, filename, color_theme=color_theme, scale=scale)\n</code></pre>"},{"location":"api/#pgx.State.to_svg","title":"<code>to_svg(*, color_theme=None, scale=None)</code>","text":"<p>Return SVG string. Useful for visualization in notebook.</p> <p>Parameters:</p> Name Type Description Default <code>color_theme</code> <code>Optional[Literal['light', 'dark']]</code> <p>xxx see also global config.</p> <code>None</code> <code>scale</code> <code>Optional[float]</code> <p>change image size. Default(None) is 1.0</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>SVG string</p> Source code in <code>pgx/core.py</code> <pre><code>def to_svg(\n    self,\n    *,\n    color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n    scale: Optional[float] = None,\n) -&gt; str:\n    \"\"\"Return SVG string. Useful for visualization in notebook.\n\n    Args:\n        color_theme (Optional[Literal[\"light\", \"dark\"]]): xxx see also global config.\n        scale (Optional[float]): change image size. Default(None) is 1.0\n\n    Returns:\n        str: SVG string\n    \"\"\"\n    from pgx._src.visualizer import Visualizer\n\n    v = Visualizer(color_theme=color_theme, scale=scale)\n    return v.get_dwg(states=self).tostring()\n</code></pre>"},{"location":"api/#pgx.Env","title":"<code>pgx.Env</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Environment class API.</p> <p>Example usage</p> <pre><code>env: Env = pgx.make(\"tic_tac_toe\")\nstate = env.init(jax.random.PRNGKey(0))\naction = jax.random.int32(4)\nstate = env.step(state, action)\n</code></pre> Source code in <code>pgx/core.py</code> <pre><code>class Env(abc.ABC):\n    \"\"\"Environment class API.\n\n    !!! example \"Example usage\"\n\n        ```py\n        env: Env = pgx.make(\"tic_tac_toe\")\n        state = env.init(jax.random.PRNGKey(0))\n        action = jax.random.int32(4)\n        state = env.step(state, action)\n        ```\n\n    \"\"\"\n\n    def __init__(self): ...\n\n    def init(self, key: PRNGKey) -&gt; State:\n        \"\"\"Return the initial state. Note that no internal state of\n        environment changes.\n\n        Args:\n            key: pseudo-random generator key in JAX. Consumed in this function.\n\n        Returns:\n            State: initial state of environment\n\n        \"\"\"\n        state = self._init(key)\n        observation = self.observe(state)\n        return state.replace(observation=observation)  # type: ignore\n\n    def step(\n        self,\n        state: State,\n        action: Array,\n        key: Optional[Array] = None,\n    ) -&gt; State:\n        \"\"\"Step function.\"\"\"\n        is_illegal = ~state.legal_action_mask[action]\n        current_player = state.current_player\n\n        # If the state is already terminated or truncated, environment does not take usual step,\n        # but return the same state with zero-rewards for all players\n        state = jax.lax.cond(\n            (state.terminated | state.truncated),\n            lambda: state.replace(rewards=jnp.zeros_like(state.rewards)),  # type: ignore\n            lambda: self._step(state.replace(_step_count=state._step_count + 1), action, key),  # type: ignore\n        )\n\n        # Taking illegal action leads to immediate game terminal with negative reward\n        state = jax.lax.cond(\n            is_illegal,\n            lambda: self._step_with_illegal_action(state, current_player),\n            lambda: state,\n        )\n\n        # All legal_action_mask elements are **TRUE** at terminal state\n        # This is to avoid zero-division error when normalizing action probability\n        # Taking any action at terminal state does not give any effect to the state\n        state = jax.lax.cond(\n            state.terminated,\n            lambda: state.replace(legal_action_mask=jnp.ones_like(state.legal_action_mask)),  # type: ignore\n            lambda: state,\n        )\n\n        observation = self.observe(state)\n        state = state.replace(observation=observation)  # type: ignore\n\n        return state\n\n    def observe(self, state: State, player_id: Optional[Array] = None) -&gt; Array:\n        \"\"\"Observation function.\"\"\"\n        if player_id is None:\n            player_id = state.current_player\n        else:\n            warnings.warn(\"[Pgx] `player_id` in `observe` is deprecated. This argument will be removed in the future.\", DeprecationWarning)\n        obs = self._observe(state, player_id)\n        return jax.lax.stop_gradient(obs)\n\n    @abc.abstractmethod\n    def _init(self, key: PRNGKey) -&gt; State:\n        \"\"\"Implement game-specific init function here.\"\"\"\n        ...\n\n    @abc.abstractmethod\n    def _step(self, state, action, key) -&gt; State:\n        \"\"\"Implement game-specific step function here.\"\"\"\n        ...\n\n    @abc.abstractmethod\n    def _observe(self, state: State, player_id: Array) -&gt; Array:\n        \"\"\"Implement game-specific observe function here.\"\"\"\n        ...\n\n    @property\n    @abc.abstractmethod\n    def id(self) -&gt; EnvId:\n        \"\"\"Environment id.\"\"\"\n        ...\n\n    @property\n    @abc.abstractmethod\n    def version(self) -&gt; str:\n        \"\"\"Environment version. Updated when behavior, parameter, or API is changed.\n        Refactoring or speeding up without any expected behavior changes will NOT update the version number.\n        \"\"\"\n        ...\n\n    @property\n    @abc.abstractmethod\n    def num_players(self) -&gt; int:\n        \"\"\"Number of players (e.g., 2 in Tic-tac-toe)\"\"\"\n        ...\n\n    @property\n    def num_actions(self) -&gt; int:\n        \"\"\"Return the size of action space (e.g., 9 in Tic-tac-toe)\"\"\"\n        state = self.init(jax.random.PRNGKey(0))\n        return int(state.legal_action_mask.shape[0])\n\n    @property\n    def observation_shape(self) -&gt; Tuple[int, ...]:\n        \"\"\"Return the matrix shape of observation\"\"\"\n        state = self.init(jax.random.PRNGKey(0))\n        obs = self._observe(state, state.current_player)\n        return obs.shape\n\n    @property\n    def _illegal_action_penalty(self) -&gt; float:\n        \"\"\"Negative reward given when illegal action is selected.\"\"\"\n        return -1.0\n\n    def _step_with_illegal_action(self, state: State, loser: Array) -&gt; State:\n        penalty = self._illegal_action_penalty\n        reward = jnp.ones_like(state.rewards) * (-1 * penalty) * (self.num_players - 1)\n        reward = reward.at[loser].set(penalty)\n        return state.replace(rewards=reward, terminated=TRUE)  # type: ignore\n</code></pre>"},{"location":"api/#pgx.Env._illegal_action_penalty","title":"<code>_illegal_action_penalty</code>  <code>property</code>","text":"<p>Negative reward given when illegal action is selected.</p>"},{"location":"api/#pgx.Env.id","title":"<code>id</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Environment id.</p>"},{"location":"api/#pgx.Env.num_actions","title":"<code>num_actions</code>  <code>property</code>","text":"<p>Return the size of action space (e.g., 9 in Tic-tac-toe)</p>"},{"location":"api/#pgx.Env.num_players","title":"<code>num_players</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Number of players (e.g., 2 in Tic-tac-toe)</p>"},{"location":"api/#pgx.Env.observation_shape","title":"<code>observation_shape</code>  <code>property</code>","text":"<p>Return the matrix shape of observation</p>"},{"location":"api/#pgx.Env.version","title":"<code>version</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Environment version. Updated when behavior, parameter, or API is changed. Refactoring or speeding up without any expected behavior changes will NOT update the version number.</p>"},{"location":"api/#pgx.Env._init","title":"<code>_init(key)</code>  <code>abstractmethod</code>","text":"<p>Implement game-specific init function here.</p> Source code in <code>pgx/core.py</code> <pre><code>@abc.abstractmethod\ndef _init(self, key: PRNGKey) -&gt; State:\n    \"\"\"Implement game-specific init function here.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#pgx.Env._observe","title":"<code>_observe(state, player_id)</code>  <code>abstractmethod</code>","text":"<p>Implement game-specific observe function here.</p> Source code in <code>pgx/core.py</code> <pre><code>@abc.abstractmethod\ndef _observe(self, state: State, player_id: Array) -&gt; Array:\n    \"\"\"Implement game-specific observe function here.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#pgx.Env._step","title":"<code>_step(state, action, key)</code>  <code>abstractmethod</code>","text":"<p>Implement game-specific step function here.</p> Source code in <code>pgx/core.py</code> <pre><code>@abc.abstractmethod\ndef _step(self, state, action, key) -&gt; State:\n    \"\"\"Implement game-specific step function here.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#pgx.Env.init","title":"<code>init(key)</code>","text":"<p>Return the initial state. Note that no internal state of environment changes.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>PRNGKey</code> <p>pseudo-random generator key in JAX. Consumed in this function.</p> required <p>Returns:</p> Name Type Description <code>State</code> <code>State</code> <p>initial state of environment</p> Source code in <code>pgx/core.py</code> <pre><code>def init(self, key: PRNGKey) -&gt; State:\n    \"\"\"Return the initial state. Note that no internal state of\n    environment changes.\n\n    Args:\n        key: pseudo-random generator key in JAX. Consumed in this function.\n\n    Returns:\n        State: initial state of environment\n\n    \"\"\"\n    state = self._init(key)\n    observation = self.observe(state)\n    return state.replace(observation=observation)  # type: ignore\n</code></pre>"},{"location":"api/#pgx.Env.observe","title":"<code>observe(state, player_id=None)</code>","text":"<p>Observation function.</p> Source code in <code>pgx/core.py</code> <pre><code>def observe(self, state: State, player_id: Optional[Array] = None) -&gt; Array:\n    \"\"\"Observation function.\"\"\"\n    if player_id is None:\n        player_id = state.current_player\n    else:\n        warnings.warn(\"[Pgx] `player_id` in `observe` is deprecated. This argument will be removed in the future.\", DeprecationWarning)\n    obs = self._observe(state, player_id)\n    return jax.lax.stop_gradient(obs)\n</code></pre>"},{"location":"api/#pgx.Env.step","title":"<code>step(state, action, key=None)</code>","text":"<p>Step function.</p> Source code in <code>pgx/core.py</code> <pre><code>def step(\n    self,\n    state: State,\n    action: Array,\n    key: Optional[Array] = None,\n) -&gt; State:\n    \"\"\"Step function.\"\"\"\n    is_illegal = ~state.legal_action_mask[action]\n    current_player = state.current_player\n\n    # If the state is already terminated or truncated, environment does not take usual step,\n    # but return the same state with zero-rewards for all players\n    state = jax.lax.cond(\n        (state.terminated | state.truncated),\n        lambda: state.replace(rewards=jnp.zeros_like(state.rewards)),  # type: ignore\n        lambda: self._step(state.replace(_step_count=state._step_count + 1), action, key),  # type: ignore\n    )\n\n    # Taking illegal action leads to immediate game terminal with negative reward\n    state = jax.lax.cond(\n        is_illegal,\n        lambda: self._step_with_illegal_action(state, current_player),\n        lambda: state,\n    )\n\n    # All legal_action_mask elements are **TRUE** at terminal state\n    # This is to avoid zero-division error when normalizing action probability\n    # Taking any action at terminal state does not give any effect to the state\n    state = jax.lax.cond(\n        state.terminated,\n        lambda: state.replace(legal_action_mask=jnp.ones_like(state.legal_action_mask)),  # type: ignore\n        lambda: state,\n    )\n\n    observation = self.observe(state)\n    state = state.replace(observation=observation)  # type: ignore\n\n    return state\n</code></pre>"},{"location":"api/#pgx.EnvId","title":"<code>pgx.EnvId = Literal['2048', 'animal_shogi', 'backgammon', 'bridge_bidding', 'chess', 'connect_four', 'gardner_chess', 'go_9x9', 'go_19x19', 'hex', 'kuhn_poker', 'leduc_holdem', 'minatar-asterix', 'minatar-breakout', 'minatar-freeway', 'minatar-seaquest', 'minatar-space_invaders', 'othello', 'shogi', 'sparrow_mahjong', 'tic_tac_toe']</code>  <code>module-attribute</code>","text":""},{"location":"api/#pgx.make","title":"<code>pgx.make(env_id)</code>","text":"<p>Load the specified environment.</p> <p>Example usage</p> <pre><code>env = pgx.make(\"tic_tac_toe\")\n</code></pre> <p><code>BridgeBidding</code> environment</p> <p><code>BridgeBidding</code> environment requires the domain knowledge of bridge game. So we forbid users to load the bridge environment by <code>make(\"bridge_bidding\")</code>. Use <code>BridgeBidding</code> class directly by <code>from pgx.bridge_bidding import BridgeBidding</code>.</p> Source code in <code>pgx/core.py</code> <pre><code>def make(env_id: EnvId):  # noqa: C901\n    \"\"\"Load the specified environment.\n\n    !!! example \"Example usage\"\n\n        ```py\n        env = pgx.make(\"tic_tac_toe\")\n        ```\n\n    !!! note \"`BridgeBidding` environment\"\n\n        `BridgeBidding` environment requires the domain knowledge of bridge game.\n        So we forbid users to load the bridge environment by `make(\"bridge_bidding\")`.\n        Use `BridgeBidding` class directly by `from pgx.bridge_bidding import BridgeBidding`.\n\n    \"\"\"\n    # NOTE: BridgeBidding environment requires the domain knowledge of bridge\n    # So we forbid users to load the bridge environment by `make(\"bridge_bidding\")`.\n    if env_id == \"2048\":\n        from pgx.play2048 import Play2048\n\n        return Play2048()\n    elif env_id == \"animal_shogi\":\n        from pgx.animal_shogi import AnimalShogi\n\n        return AnimalShogi()\n    elif env_id == \"backgammon\":\n        from pgx.backgammon import Backgammon\n\n        return Backgammon()\n    elif env_id == \"chess\":\n        from pgx.chess import Chess\n\n        return Chess()\n    elif env_id == \"connect_four\":\n        from pgx.connect_four import ConnectFour\n\n        return ConnectFour()\n    elif env_id == \"gardner_chess\":\n        from pgx.gardner_chess import GardnerChess\n\n        return GardnerChess()\n    elif env_id == \"go_9x9\":\n        from pgx.go import Go\n\n        return Go(size=9, komi=7.5)\n    elif env_id == \"go_19x19\":\n        from pgx.go import Go\n\n        return Go(size=19, komi=7.5)\n    elif env_id == \"hex\":\n        from pgx.hex import Hex\n\n        return Hex()\n    elif env_id == \"kuhn_poker\":\n        from pgx.kuhn_poker import KuhnPoker\n\n        return KuhnPoker()\n    elif env_id == \"leduc_holdem\":\n        from pgx.leduc_holdem import LeducHoldem\n\n        return LeducHoldem()\n    # elif env_id == \"mahjong\":\n    #     from pgx.mahjong import Mahjong\n\n    #     return Mahjong()\n    elif env_id == \"minatar-asterix\":\n        from pgx.minatar.asterix import MinAtarAsterix  # type: ignore\n\n        return MinAtarAsterix()\n    elif env_id == \"minatar-breakout\":\n        from pgx.minatar.breakout import MinAtarBreakout  # type: ignore\n\n        return MinAtarBreakout()\n    elif env_id == \"minatar-freeway\":\n        from pgx.minatar.freeway import MinAtarFreeway  # type: ignore\n\n        return MinAtarFreeway()\n    elif env_id == \"minatar-seaquest\":\n        from pgx.minatar.seaquest import MinAtarSeaquest  # type: ignore\n\n        return MinAtarSeaquest()\n    elif env_id == \"minatar-space_invaders\":\n        from pgx.minatar.space_invaders import MinAtarSpaceInvaders  # type: ignore\n\n        return MinAtarSpaceInvaders()\n    elif env_id == \"othello\":\n        from pgx.othello import Othello\n\n        return Othello()\n    elif env_id == \"shogi\":\n        from pgx.shogi import Shogi\n\n        return Shogi()\n    elif env_id == \"sparrow_mahjong\":\n        from pgx.sparrow_mahjong import SparrowMahjong\n\n        return SparrowMahjong()\n    elif env_id == \"tic_tac_toe\":\n        from pgx.tic_tac_toe import TicTacToe\n\n        return TicTacToe()\n    else:\n        envs = \"\\n\".join(available_envs())\n        raise ValueError(f\"Wrong env_id '{env_id}' is passed. Available ids are: \\n{envs}\")\n</code></pre>"},{"location":"api/#pgx.available_envs","title":"<code>pgx.available_envs()</code>","text":"<p>List up all environment id available in <code>pgx.make</code> function.</p> <p>Example usage</p> <pre><code>pgx.available_envs()\n('2048', 'animal_shogi', 'backgammon', 'chess', 'connect_four', 'go_9x9', 'go_19x19', 'hex', 'kuhn_poker', 'leduc_holdem', 'minatar-asterix', 'minatar-breakout', 'minatar-freeway', 'minatar-seaquest', 'minatar-space_invaders', 'othello', 'shogi', 'sparrow_mahjong', 'tic_tac_toe')\n</code></pre> <p><code>BridgeBidding</code> environment</p> <p><code>BridgeBidding</code> environment requires the domain knowledge of bridge game. So we forbid users to load the bridge environment by <code>make(\"bridge_bidding\")</code>. Use <code>BridgeBidding</code> class directly by <code>from pgx.bridge_bidding import BridgeBidding</code>.</p> Source code in <code>pgx/core.py</code> <pre><code>def available_envs() -&gt; Tuple[EnvId, ...]:\n    \"\"\"List up all environment id available in `pgx.make` function.\n\n    !!! example \"Example usage\"\n\n        ```py\n        pgx.available_envs()\n        ('2048', 'animal_shogi', 'backgammon', 'chess', 'connect_four', 'go_9x9', 'go_19x19', 'hex', 'kuhn_poker', 'leduc_holdem', 'minatar-asterix', 'minatar-breakout', 'minatar-freeway', 'minatar-seaquest', 'minatar-space_invaders', 'othello', 'shogi', 'sparrow_mahjong', 'tic_tac_toe')\n        ```\n\n\n    !!! note \"`BridgeBidding` environment\"\n\n        `BridgeBidding` environment requires the domain knowledge of bridge game.\n        So we forbid users to load the bridge environment by `make(\"bridge_bidding\")`.\n        Use `BridgeBidding` class directly by `from pgx.bridge_bidding import BridgeBidding`.\n\n    \"\"\"\n    games = get_args(EnvId)\n    games = tuple(filter(lambda x: x != \"bridge_bidding\", games))\n    return games\n</code></pre>"},{"location":"api/#pgx.set_visualization_config","title":"<code>pgx.set_visualization_config(*, color_theme='light', scale=1.0, frame_duration_seconds=0.2)</code>","text":"Source code in <code>pgx/_src/visualizer.py</code> <pre><code>def set_visualization_config(\n    *,\n    color_theme: ColorTheme = \"light\",\n    scale: float = 1.0,\n    frame_duration_seconds: float = 0.2,\n):\n    global_config.color_theme = color_theme\n    global_config.scale = scale\n    global_config.frame_duration_seconds = frame_duration_seconds\n</code></pre>"},{"location":"api/#pgx.save_svg","title":"<code>pgx.save_svg(state, filename, *, color_theme=None, scale=None)</code>","text":"Source code in <code>pgx/_src/visualizer.py</code> <pre><code>def save_svg(\n    state: State,\n    filename: Union[str, Path],\n    *,\n    color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n    scale: Optional[float] = None,\n) -&gt; None:\n    if state.env_id.startswith(\"minatar\"):\n        state.save_svg(filename=filename)\n    else:\n        v = Visualizer(color_theme=color_theme, scale=scale)\n        v.get_dwg(states=state).saveas(filename)\n</code></pre>"},{"location":"api/#pgx.save_svg_animation","title":"<code>pgx.save_svg_animation(states, filename, *, color_theme=None, scale=None, frame_duration_seconds=None)</code>","text":"Source code in <code>pgx/_src/visualizer.py</code> <pre><code>def save_svg_animation(\n    states: Sequence[State],\n    filename: Union[str, Path],\n    *,\n    color_theme: Optional[Literal[\"light\", \"dark\"]] = None,\n    scale: Optional[float] = None,\n    frame_duration_seconds: Optional[float] = None,\n) -&gt; None:\n    assert not states[0].env_id.startswith(\"minatar\"), \"MinAtar does not support svg animation.\"\n    v = Visualizer(color_theme=color_theme, scale=scale)\n\n    if frame_duration_seconds is None:\n        frame_duration_seconds = global_config.frame_duration_seconds\n\n    frame_groups = []\n    dwg = None\n    for i, state in enumerate(states):\n        dwg = v.get_dwg(states=state)\n        assert (\n            len([e for e in dwg.elements if type(e) is svgwrite.container.Group]) == 1\n        ), \"Drawing must contain only one group\"\n        group: svgwrite.container.Group = dwg.elements[-1]\n        group[\"id\"] = f\"_fr{i:x}\"  # hex frame number\n        group[\"class\"] = \"frame\"\n        frame_groups.append(group)\n\n    assert dwg is not None\n    del dwg.elements[-1]\n    total_seconds = frame_duration_seconds * len(frame_groups)\n\n    style = f\".frame{{visibility:hidden; animation:{total_seconds}s linear _k infinite;}}\"\n    style += f\"@keyframes _k{{0%,{100/len(frame_groups)}%{{visibility:visible}}{100/len(frame_groups) * 1.000001}%,100%{{visibility:hidden}}}}\"\n\n    for i, group in enumerate(frame_groups):\n        dwg.add(group)\n        style += f\"#{group['id']}{{animation-delay:{i * frame_duration_seconds}s}}\"\n    dwg.defs.add(svgwrite.container.Style(content=style))\n    dwg.saveas(filename)\n</code></pre>"},{"location":"api/#pgx.BaselineModelId","title":"<code>pgx.BaselineModelId = Literal['animal_shogi_v0', 'gardner_chess_v0', 'go_9x9_v0', 'hex_v0', 'othello_v0', 'minatar-asterix_v0', 'minatar-breakout_v0', 'minatar-freeway_v0', 'minatar-seaquest_v0', 'minatar-space_invaders_v0']</code>  <code>module-attribute</code>","text":""},{"location":"api/#pgx.make_baseline_model","title":"<code>pgx.make_baseline_model(model_id, download_dir='baselines')</code>","text":"Source code in <code>pgx/_src/baseline.py</code> <pre><code>def make_baseline_model(model_id: BaselineModelId, download_dir: str = \"baselines\"):\n    if model_id in (\n        \"animal_shogi_v0\",\n        \"gardner_chess_v0\",\n        \"go_9x9_v0\",\n        \"hex_v0\",\n        \"othello_v0\",\n    ):\n        return _make_az_baseline_model(model_id, download_dir)\n    elif model_id in (\n        \"minatar-asterix_v0\",\n        \"minatar-breakout_v0\",\n        \"minatar-freeway_v0\",\n        \"minatar-seaquest_v0\",\n        \"minatar-space_invaders_v0\",\n    ):\n        return _make_minatar_baseline_model(model_id, download_dir)\n    else:\n        assert False\n</code></pre>"},{"location":"api/#pgx.api_test","title":"<code>pgx.api_test(env, num=100, use_key=True)</code>","text":"Source code in <code>pgx/_src/api_test.py</code> <pre><code>def api_test(env: Env, num: int = 100, use_key=True):\n    api_test_single(env, num, use_key)\n    api_test_batch(env, num, use_key)\n</code></pre>"},{"location":"api_usage/","title":"Pgx API Usage","text":""},{"location":"api_usage/#example1-random-play","title":"Example.1: Random play","text":"<pre><code>import jax\nimport jax.numpy as jnp\nimport pgx\n\nseed = 42\nbatch_size = 10\nkey = jax.random.PRNGKey(seed)\n\n\ndef act_randomly(rng_key, obs, mask):\n    \"\"\"Ignore observation and choose randomly from legal actions\"\"\"\n    del obs\n    probs = mask / mask.sum()\n    logits = jnp.maximum(jnp.log(probs), jnp.finfo(probs.dtype).min)\n    return jax.random.categorical(rng_key, logits=logits, axis=-1)\n\n\n# Load the environment\nenv = pgx.make(\"go_9x9\")\ninit_fn = jax.jit(jax.vmap(env.init))\nstep_fn = jax.jit(jax.vmap(env.step))\n\n# Initialize the states\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, batch_size)\nstate = init_fn(keys)\n\n# Run random simulation\nwhile not (state.terminated | state.truncated).all():\n    key, subkey = jax.random.split(key)\n    action = act_randomly(subkey, state.observation, state.legal_action_mask)\n    state = step_fn(state, action)  # state.reward (2,)\n</code></pre>"},{"location":"api_usage/#example2-random-agent-vs-baseline-model","title":"Example.2: Random agent vs Baseline model","text":"<p>This illustrative example helps to understand</p> <ul> <li>How <code>state.current_player</code> is defined</li> <li>How to access the reward of each player</li> <li>How <code>Env.step</code> behaves against already terminated states</li> <li>How to use baseline models probided by Pgx</li> </ul> <pre><code>import jax\nimport jax.numpy as jnp\nimport pgx\nfrom pgx.experimental.utils import act_randomly\n\nseed = 42\nbatch_size = 10\nkey = jax.random.PRNGKey(seed)\n\n# Prepare agent A and B\n#   Agent A: random player\n#   Agent B: baseline player provided by Pgx\nA = 0\nB = 1\n\n# Load the environment\nenv = pgx.make(\"go_9x9\")\ninit_fn = jax.jit(jax.vmap(env.init))\nstep_fn = jax.jit(jax.vmap(env.step))\n\n# Prepare baseline model\n# Note that it additionaly requires Haiku library ($ pip install dm-haiku)\nmodel_id = \"go_9x9_v0\"\nmodel = pgx.make_baseline_model(model_id)\n\n# Initialize the states\nkey, subkey = jax.random.split(key)\nkeys = jax.random.split(subkey, batch_size)\nstate = init_fn(keys)\nprint(f\"Game index: {jnp.arange(batch_size)}\")  #  [0 1 2 3 4 5 6 7 8 9]\nprint(f\"Black player: {state.current_player}\")  #  [1 1 0 1 0 0 1 1 1 1]\n# In other words\nprint(f\"A is black: {state.current_player == A}\")  # [False False  True False  True  True False False False False]\nprint(f\"B is black: {state.current_player == B}\")  # [ True  True False  True False False  True  True  True  True]\n\n# Run simulation\nR = state.rewards\nwhile not (state.terminated | state.truncated).all():\n    # Action of random player A\n    key, subkey = jax.random.split(key)\n    action_A = jax.jit(act_randomly)(subkey, state)\n    # Greedy action of baseline model B\n    logits, value = model(state.observation)\n    action_B = logits.argmax(axis=-1)\n\n    action = jnp.where(state.current_player == A, action_A, action_B)\n    state = step_fn(state, action)\n    R += state.rewards\n\nprint(f\"Return of agent A = {R[:, A]}\")  # [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\nprint(f\"Return of agent B = {R[:, B]}\")  # [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n</code></pre> <p>Note that we can avoid to explicitly deal with the first batch dimension like <code>[:, A]</code> by using <code>vmap</code> later.</p>"},{"location":"backgammon/","title":"Backgammon","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"backgammon/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"backgammon\")\n</code></pre> <p>or you can directly load <code>Backgammon</code> class</p> <pre><code>from pgx.backgammon import Backgammon\n\nenv = Backgammon()\n</code></pre>"},{"location":"backgammon/#description","title":"Description","text":"<p>Backgammon is a two-player board game played with counters and dice on tables boards. It is the most widespread Western member of the large family of tables games, whose ancestors date back nearly 5,000 years to the regions of Mesopotamia and Persia. The earliest record of backgammon itself dates to 17th-century England, being descended from the 16th-century game of Irish.</p> <p>Backgammon is a two-player game of contrary movement in which each player has fifteen pieces known traditionally as men (short for 'tablemen'), but increasingly known as 'checkers' in the US in recent decades, analogous to the other board game of Checkers. The backgammon table pieces move along twenty-four 'points' according to the roll of two dice. The objective of the game is to move the fifteen pieces around the board and be first to bear off, i.e., remove them from the board. The achievement of this while the opponent is still a long way behind results in a triple win known as a backgammon, hence the name of the game.</p> <p>Backgammon involves a combination of strategy and luck (from rolling dice). While the dice may determine the outcome of a single game, the better player will accumulate the better record over a series of many games. With each roll of the dice, players must choose from numerous options for moving their pieces and anticipate possible counter-moves by the opponent. The optional use of a doubling cube allows players to raise the stakes during the game.</p> <p>Wikipedia</p>"},{"location":"backgammon/#specs","title":"Specs","text":"Name Value Version <code>v1</code> Number of players <code>2</code> Number of actions <code>156 (= 6 * 26)</code> Observation shape <code>(34,)</code> Observation type <code>int</code> Rewards <code>{-3, -2, -1, 0, 1, 2, 3}</code>"},{"location":"backgammon/#observation","title":"Observation","text":"<p>The first <code>28</code> observation dimensions follow <code>[Antonoglou+22]</code>:</p> <p>In our backgammon experiments, the board was represented using a vector of size 28, with the first 24 positions representing the number of chips for each player in the 24 possible points on the board, and the last four representing the number of hit chips and born off chips for each of the two players. We used positive numbers for the current player\u2019s chips and negative ones for her opponent.</p> Index Description <code>[:24]</code> Number of checkers on each position <code>[24:26]</code> Number of checkers on bar <code>[26:28]</code> Number of checkers brone off <code>[28:34]</code> Number of available moves for each die number"},{"location":"backgammon/#action","title":"Action","text":"<p>Action design is same as micro-action in <code>[Antonoglou+22]</code>:</p> <p>An action in our implementation consists of 4 micro-actions, the same as the maximum number of dice a player can play at each turn.  Each micro-action encodes the source position of a chip along with the value of the die used. We consider 26 possible source positions, with the 0th position corresponding to a no-op, the 1st to retrieving a chip from the hit pile, and the remaining to selecting a chip in one of the 24 possible points.   Each micro-action is encoded as a single integer with micro-action = src \u00b7 6 + die.</p> <p>The difference is that after every micro-action, the state transition happens. The turn of the same player can continue up to 4 times.</p>"},{"location":"backgammon/#rewards","title":"Rewards","text":"<p>The game payoff is rewarded.</p>"},{"location":"backgammon/#termination","title":"Termination","text":"<p>Continues until either player wins.</p>"},{"location":"backgammon/#version-history","title":"Version History","text":"<ul> <li><code>v2</code>: Specify rng key explicitly (API v2) by @sotetsuk in #1058 (v2.0.0)</li> <li><code>v1</code>: Remove redundant actions (From <code>162</code> to <code>156</code>) by @nissymori in #1004 (v1.2.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"backgammon/#reference","title":"Reference","text":"<ol> <li><code>[Antonoglou+22]</code> \"Planning in Stochastic Environments with a Learned Model\", ICLR</li> </ol>"},{"location":"bridge_bidding/","title":"Bridge bidding","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"bridge_bidding/#usage","title":"Usage","text":"<p>Bridge bidding requires domain knowledge</p> <p>To appropriately use bridge bidding environment, you need to understand the rules of contract bridge well. To avoid wrong usage, we do not provide <code>pgx.make(\"bridge_bidding\")</code>. Instead, you have to directly load <code>BridgeBidding</code> class.</p> <pre><code>from pgx.bridge_bidding import BridgeBidding\n\nenv = BridgeBidding()\n</code></pre> <p>In Pgx, we follow <code>[Tian+20]</code> and use pre-computed Double Dummy Solver (DDS) dataset for each hand. So, <code>BrdigeBidding</code> environment requires to load pre-computed DDS dataset by <code>env = BridgeBidding(\"&lt;path_to_dataset&gt;\")</code>. Please run the following command to download the DDS results provided by Pgx from huggingface.</p> <pre><code>from pgx.bridge_bidding import download_dds_results\ndownload_dds_results()\n</code></pre> <p>You can specify which pre-coumpted DDS dataset to use by passing argument to <code>BridgeBidding</code> constructor. Typically, you have to use different DDS datasets for training and testing (evaluation). To make your own DDS datasets, follow the instruction at sotetsuk/make-dds-dataset.</p>"},{"location":"bridge_bidding/#description","title":"Description","text":"<p>Contract bridge, or simply bridge, is a trick-taking card game using a standard 52-card deck. In its basic format, it is played by four players in two competing partnerships,[1] with partners sitting opposite each other around a table. Millions of people play bridge worldwide in clubs, tournaments, online and with friends at home, making it one of the world's most popular card games, particularly among seniors.</p> <p>...</p> <p>The game consists of a number of deals, each progressing through four phases. The cards are dealt to the players; then the players call (or bid) in an auction seeking to take the contract, specifying how many tricks the partnership receiving the contract (the declaring side) needs to take to receive points for the deal. During the auction, partners use their bids to exchange information about their hands, including overall strength and distribution of the suits; no other means of conveying or implying any information is permitted. The cards are then played, the declaring side trying to fulfill the contract, and the defenders trying to stop the declaring side from achieving its goal. The deal is scored based on the number of tricks taken, the contract, and various other factors which depend to some extent on the variation of the game being played.</p> <p>Contract bridge</p> <p>We follow the previous works <code>[Rong+19,Gong+19,Tian+20,Lockhart+20]</code> and focus only on the bidding phase of contract bridge. Therefore, we approximate the playing phase of bridge by using the results of DDS (Double Dummy Solver).</p>"},{"location":"bridge_bidding/#specs","title":"Specs","text":"Name Value Version <code>v1</code> Number of players <code>4</code> Number of actions <code>38</code> Observation shape <code>(480,)</code> Observation type <code>bool</code> Rewards Game payoff"},{"location":"bridge_bidding/#observation","title":"Observation","text":"<p>We follow the observation design of <code>[Lockhart+20]</code>, OpenSpiel.</p> Index Description <code>obs[0:4]</code> Vulnerability <code>obs[4:8]</code> Per player, did this player pass before the opening bid? <code>obs[8:20]</code> Per player played bid, double, redouble against 1\u2667 ... ... <code>obs[416:428]</code> Per player played bid, double, redouble against 7NT <code>obs[428:480]</code> 13-hot vector indicating the cards we hold"},{"location":"bridge_bidding/#action","title":"Action","text":"<p>Each action <code>(0, ..., 37)</code> corresponds to <code>(Pass, Double, Redouble, 1\u2667, 1\u2662, 1\u2661, 1\u2664, 1NT, ..., 7\u2667, 7\u2662, 7\u2661, 7\u2664, 7NT)</code>, respectively.</p> Index Description <code>0</code> <code>Pass</code> <code>1</code> <code>Double</code> <code>2</code> <code>Redouble</code> <code>3, ..., 7</code> <code>1\u2667, 1\u2662, 1\u2661, 1\u2664, 1NT</code> ... ... <code>33, ..., 37</code> <code>7\u2667, 7\u2662, 7\u2661, 7\u2664, 7NT</code>"},{"location":"bridge_bidding/#rewards","title":"Rewards","text":"<p>Players get the game payoff at the end of the game.</p>"},{"location":"bridge_bidding/#termination","title":"Termination","text":"<p>Terminates by three consecutive passes after the last bid.</p>"},{"location":"bridge_bidding/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> <li><code>v1</code> : Provide larger DDS dataset and improve the efficienct in #1191 (v2.1.2)</li> </ul>"},{"location":"bridge_bidding/#reference","title":"Reference","text":"<ul> <li><code>[Rong+19]</code> \"Competitive Bridge Bidding with Deep Neural Networks\"</li> <li><code>[Gong+19]</code> \"Simple is Better: Training an End-to-end Contract Bridge Bidding Agent without Human Knowledge\"</li> <li><code>[Tian+20]</code> \"Joint Policy Search for Multi-agent Collaboration with Imperfect Information\"</li> <li><code>[Lockhart+20]</code> \"Human-agent cooperation in bridge bidding\"</li> <li><code>Double Dummy Solver</code> http://privat.bahnhof.se/wb758135/</li> <li><code>PBN format</code> https://www.tistis.nl/pbn/ </li> <li><code>IMP</code> https://en.wikipedia.org/wiki/International_Match_Points</li> </ul>"},{"location":"chess/","title":"Chess","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"chess/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"chess\")\n</code></pre> <p>or you can directly load <code>Chess</code> class</p> <pre><code>from pgx.chess import Chess\n\nenv = Chess()\n</code></pre>"},{"location":"chess/#description","title":"Description","text":"<p>Chess is a board game for two players, called White and Black, each controlling an army of chess pieces in their color, with the objective to checkmate the opponent's king. It is sometimes called international chess or Western chess to distinguish it from related games such as xiangqi (Chinese chess) and shogi (Japanese chess). The recorded history of chess goes back at least to the emergence of a similar game, chaturanga, in seventh century India. The rules of chess as they are known today emerged in Europe at the end of the 15th century, with standardization and universal acceptance by the end of the 19th century. Today, chess is one of the world's most popular games played by millions of people worldwide.</p> <p>Chess is an abstract strategy game that involves no hidden information and no elements of chance. It is played on a chessboard with 64 squares arranged in an 8\u00d78 grid. At the start, each player controls sixteen pieces: one king, one queen, two rooks, two bishops, two knights, and eight pawns. White moves first, followed by Black. The game is won by checkmating the opponent's king, i.e. threatening it with inescapable capture. There are also several ways a game can end in a draw.</p> <p>Chess - Wikipedia</p>"},{"location":"chess/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>4672</code> Observation shape <code>(8, 8, 119)</code> Observation type <code>float</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"chess/#observation","title":"Observation","text":"<p>We follow the observation design of AlphaZero <code>[Silver+18]</code>. P1 denotes the current player, and P2 denotes the opponent.</p> Index Description <code>[0:6]</code> P1 board @ 0-steps before <code>[6:12]</code> P2 board @ 0-steps before <code>[12:14]</code> Repetitions @ 0-steps before ... (@ 1-7 steps before) <code>[112]</code> Color <code>[113]</code> Total move count <code>[114:116]</code> P1 castling <code>[116:118]</code> P2 castling <code>[118]</code> No progress count"},{"location":"chess/#action","title":"Action","text":"<p>We also follow the action design of AlphaZero <code>[Silver+18]</code>. There are <code>4672 = 64 x 73</code> possible actions. Each action represents</p> <ul> <li>64 source position (<code>action // 73</code>), and</li> <li>73 moves (<code>action % 73</code>)</li> </ul> <p>Moves are defined by 56 queen moves, 8 knight moves, and 9 underpromotions.</p>"},{"location":"chess/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"chess/#termination","title":"Termination","text":"<p>Termination occurs when one of the following conditions are satisfied:</p> <ol> <li>checkmate</li> <li>stalemate</li> <li>no sufficient pieces to checkmate</li> <li>Threefold repetition</li> <li><code>50</code> halfmoves are elapsed without any captures or pawn moves</li> <li><code>512</code> steps are elapsed (from AlphaZero <code>[Silver+18]</code>)</li> </ol>"},{"location":"chess/#version-history","title":"Version History","text":"<ul> <li><code>v2</code> : Bug fix of wrong zobrist hash by @sotetsuk in #1078 (v2.0.0) </li> <li><code>v1</code> : Bug fix when castling by @HongruiTang in #983 (v1.1.0) </li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul> <p>Well-tested</p> <p>Pgx chess implementation is well-tested. You can confirm that its behavior is identical to the throughly-tested OpenSpiel implementation by this colab.</p>"},{"location":"chess/#reference","title":"Reference","text":"<ul> <li><code>[Silver+18]</code> \"A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play\" Science</li> </ul>"},{"location":"connect_four/","title":"Connect four","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"connect_four/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"connect_four\")\n</code></pre> <p>or you can directly load <code>ConnectFour</code> class</p> <pre><code>from pgx.connect_four import ConnectFour\n\nenv = ConnectFour()\n</code></pre>"},{"location":"connect_four/#description","title":"Description","text":"<p>Connect Four is a two-player connection rack game, in which the players choose a color and then take turns dropping colored tokens into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own tokens.</p> <p>Wikipedia</p>"},{"location":"connect_four/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>7</code> Observation shape <code>(6, 7, 2)</code> Observation type <code>bool</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"connect_four/#observation","title":"Observation","text":"Index Description <code>[:, :, 0]</code> represents <code>(6, 7)</code> squares filled by the current player <code>[:, :, 1]</code> represents <code>(6, 7)</code> squares filled by the opponent player of current player"},{"location":"connect_four/#action","title":"Action","text":"<p>Each action represents the column index the player drops the token to.</p>"},{"location":"connect_four/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"connect_four/#termination","title":"Termination","text":"<p>Termination happens when </p> <ol> <li>either one player places four of their tokens in a row (horizontally, vertically, or diagonally), or </li> <li>all <code>42 (= 6 x 7)</code> squares are filled.</li> </ol>"},{"location":"connect_four/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"gardner_chess/","title":"Gardner chess","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"gardner_chess/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"gardner_chess\")\n</code></pre> <p>or you can directly load <code>GardnerChess</code> class</p> <pre><code>from pgx.gardner_chess import GardnerChess\n\nenv = GardnerChess()\n</code></pre>"},{"location":"gardner_chess/#description","title":"Description","text":"<p>A board needs to be five squares wide to contain all kinds of chess pieces on the first row. In 1969, Martin Gardner suggested a chess variant on 5\u00d75 board in which all chess moves, including pawn double-move, en-passant capture as well as castling can be made. Later AISE (Associazione Italiana Scacchi Eterodossi, \"Italian Heterodox Chess Association\") abandoned pawn double-move and castling. The game was largely played in Italy (including by correspondence) and opening theory was developed. </p> <p>Minichess - Wikipedia</p> <p>Pgx implementation does not support pawn double-move, en-passant and castling.</p>"},{"location":"gardner_chess/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>1225</code> Observation shape <code>(5, 5, 115)</code> Observation type <code>float</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"gardner_chess/#observation","title":"Observation","text":"<p>We follow the observation design of AlphaZero <code>[Silver+18]</code>. P1 denotes the current player, and P2 denotes the opponent.</p> Index Description <code>[:, :, 0:6]</code> P1 board @ 0-steps before <code>[:, :, 6:12]</code> P2 board @ 0-steps before <code>[:, :, 12:14]</code> Repetitions @ 0-steps before ... (@ 1-7 steps before) <code>[:, :, 112]</code> Color <code>[:, :, 113]</code> Total move count <code>[:, :, 114]</code> No progress count"},{"location":"gardner_chess/#action","title":"Action","text":"<p>We also follow the action design of AlphaZero <code>[Silver+18]</code>. There are <code>1225 = 25 x 49</code> possible actions. Each action represents</p> <ul> <li>25 source position (<code>action // 49</code>), and</li> <li>49 moves (<code>action % 49</code>)</li> </ul> <p>Moves are defined by 32 queen moves, 8 knight moves, and 9 underpromotions.</p>"},{"location":"gardner_chess/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"gardner_chess/#termination","title":"Termination","text":"<p>Termination occurs when one of the following conditions are satisfied:</p> <ol> <li>checkmate</li> <li>stalemate</li> <li>no sufficient pieces to checkmate</li> <li>threefold repetition</li> <li><code>50</code> halfmoves are elapsed without any captures or pawn moves</li> <li><code>256</code> steps are elapsed (<code>512</code> in full-size chess experiments in AlphaZero <code>[Silver+18]</code>)</li> </ol>"},{"location":"gardner_chess/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"gardner_chess/#baseline-models","title":"Baseline models","text":"<p>Pgx offers a baseline model for Gardner Chess. Users can use it for an anchor opponent in evaluation. See our paper for more details. See this colab for how to use it.</p> Model ID Description <code>gardner_chess_v0</code> See our paper for the training details."},{"location":"gardner_chess/#reference","title":"Reference","text":"<ul> <li><code>[Silver+18]</code> \"A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play\" Science </li> </ul>"},{"location":"go/","title":"Go","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"go/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"go_19x19\")  # or \"go_9x9\"\n</code></pre> <p>or you can directly load <code>Go</code> class</p> <pre><code>from pgx.go import Go\n\nenv = Go(size=19, komi=7.5)\n</code></pre>"},{"location":"go/#description","title":"Description","text":"<p>Go is an abstract strategy board game for two players in which the aim is to surround more territory than the opponent. The game was invented in China more than 2,500 years ago and is believed to be the oldest board game continuously played to the present day.</p> <p>Wikipedia</p>"},{"location":"go/#rules","title":"Rules","text":"<p>The rule implemented in Pgx follows Tromp-Taylor Rules.</p> <p>Note</p> <p>By default, we use <code>7.5</code>. Users can set different <code>komi</code> at <code>Go</code> class constructor.</p> <p>Note</p> <p>The Tromp-Taylor rule enforces PSK (Positional Superko). However, strictly implementing PSK to determine legal moves is inefficient, as it requires computing the hash for all possible subsequent board states. Since PSK rarely occurs\u2014based on our best knowledge\u2014most implementations compromise. For example:</p> <p>OpenSpiel uses SSK (Situational Superko) instead of PSK to compute legal moves, and if a PSK move occurs, the game ends in a tie. PettingZoo also uses SSK for legal moves but ignores PSK moves altogether. The strict rule is: \"PSK for legal moves, and any PSK move results in an immediate loss.\" Like others, we also compromise. Our approach is similar to OpenSpiel:</p> <p>Pgx uses SSK for legal moves, but any PSK move results in an immediate loss. Overall, we believe the impact of this compromise is minimal, especially on a 19x19 board, since PSK scenarios are rare.</p> Tromp-Taylor OpenSpiel PettingZoo Pgx legal action PSK SSK SSK SSK PSK occurrence loss tie ignore (SSK) loss"},{"location":"go/#specs","title":"Specs","text":"<p>Let <code>N</code> be the board size (e.g., <code>19</code>).</p> Name Value Version <code>v1</code> Number of players <code>2</code> Number of actions <code>N x N + 1</code> Observation shape <code>(N, N, 17)</code> Observation type <code>bool</code> Rewards <code>{-1, 1}</code>"},{"location":"go/#observation","title":"Observation","text":"<p>We follow the observation design of AlphaGo Zero <code>[Silver+17]</code>.</p> Index Description <code>obs[:, :, 0]</code> stones of <code>player_id</code>          (@ current board) <code>obs[:, :, 1]</code> stones of <code>player_id</code>'s opponent (@ current board) <code>obs[:, :, 2]</code> stones of <code>player_id</code>          (@ 1-step before) <code>obs[:, :, 3]</code> stones of <code>player_id</code>'s opponent (@ 1-step before) ... ... <code>obs[:, :, -1]</code> color of <code>player_id</code> <p>Note</p> <p>For the final dimension, there are two possible options:</p> <ul> <li>Use the color of current player to play</li> <li>Use the color of <code>player_id</code></li> </ul> <p>This ambiguity happens because <code>observe</code> function is available even if <code>player_id</code> is different from <code>state.current_player</code>. In AlphaGo Zero paper <code>[Silver+17]</code>, the final dimension C is explained as:</p> <p>The final feature plane, C, represents the colour to play, and has a constant value of either 1 if black     is to play or 0 if white is to play.</p> <p>however, it also describes as</p> <p>the colour feature C is necessary because the komi is not observable.</p> <p>So, we use player_id's color to let the agent know komi information. As long as it's called when <code>player_id == state.current_player</code>, this doesn't matter.</p>"},{"location":"go/#action","title":"Action","text":"<p>Each action (<code>{0, ..., N * N - 1}</code>) represents the point to be colored. The final action represents pass action.</p>"},{"location":"go/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code>"},{"location":"go/#termination","title":"Termination","text":"<p>Termination happens when </p> <ol> <li>either one plays two consecutive passes, or</li> <li><code>N * N * 2</code> steps are elapsed <code>[Silver+17]</code>.</li> </ol>"},{"location":"go/#version-history","title":"Version History","text":"<ul> <li><code>v1</code> : Superko rule change in #1224 (v2.4.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"go/#reference","title":"Reference","text":"<ol> <li><code>[Silver+17]</code> \"Mastering the game of go without human knowledge\" Nature</li> </ol>"},{"location":"go/#baseline-models","title":"Baseline models","text":"<p>Pgx offers a baseline model for Go (9x9). Users can use it for an anchor opponent in evaluation. See our paper for more details. See this colab for how to use it.</p> Model ID Description <code>go_9x9_v0</code> See our paper for the training details."},{"location":"hex/","title":"Hex","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"hex/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"hex\")\n</code></pre> <p>or you can directly load <code>Hex</code> class</p> <pre><code>from pgx.hex import Hex\n\nenv = Hex()\n</code></pre>"},{"location":"hex/#description","title":"Description","text":"<p>Hex is a two player abstract strategy board game in which players attempt to connect opposite sides of a rhombus-shaped board made of hexagonal cells. Hex was invented by mathematician and poet Piet Hein in 1942 and later rediscovered and popularized by John Nash.</p> <p>Wikipedia</p>"},{"location":"hex/#rules","title":"Rules","text":"<p>As the first player to move has a distinct advantage, the swap rule is used to compensate for this. The detailed swap rule used in Pgx follows swap pieces:</p> <p>\"Swap pieces\": The players perform the swap by switching pieces. This means the initial red piece is replaced by a blue piece in the mirror image position, where the mirroring takes place with respect to the board's long diagonal. For example, a red piece at a3 becomes a blue piece at c1. The players do not switch colours: Red stays Red and Blue stays Blue. After the swap, it is Red's turn.</p> <p>Hex Wiki - Swap rule</p>"},{"location":"hex/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>122 (= 11 x 11) + 1</code> Observation shape <code>(11, 11, 4)</code> Observation type <code>bool</code> Rewards <code>{-1, 1}</code>"},{"location":"hex/#observation","title":"Observation","text":"Index Description <code>[:, :, 0]</code> represents <code>(11, 11)</code> cells filled by <code>player_id</code> <code>[:, :, 1]</code> represents <code>(11, 11)</code> cells filled by the opponent player of <code>player_id</code> <code>[:, :, 2]</code> represents whether <code>player_id</code> is black or white <code>[:, :, 3]</code> represents whether swap is legal or not"},{"location":"hex/#action","title":"Action","text":"<p>Each action (<code>{0, ... 120}</code>) represents the cell index to be filled. The final action <code>121</code> is the swap action available only at the second turn.</p>"},{"location":"hex/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> <p>Note that there is no draw in Hex.</p>"},{"location":"hex/#termination","title":"Termination","text":"<p>Termination happens when either one player connect opposite sides of the board.</p>"},{"location":"hex/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"hex/#baseline-models","title":"Baseline models","text":"<p>Pgx offers a baseline model for Hex. Users can use it for an anchor opponent in evaluation. See our paper for more details. See this colab for how to use it.</p> Model ID Description <code>hex_v0</code> See our paper for the training details."},{"location":"kuhn_poker/","title":"Kuhn poker","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"kuhn_poker/#description","title":"Description","text":"<p>Kuhn poker is a simplified poker with three cards: J, Q, and K.</p>"},{"location":"kuhn_poker/#rules","title":"Rules","text":"<p>Each player is dealt one card and the remaining card is unused. There are two actions: bet and pass and five possible scenarios.</p> <ol> <li><code>bet (1st) - bet (2nd)</code> : Showdown and the winner takes <code>+2</code></li> <li><code>bet (1st) - pass (2nd)</code> : 1st player takes <code>+1</code></li> <li><code>pass (1st) - pass (2nd)</code> : Showdown and the winner takes <code>+1</code></li> <li><code>pass (1st) - bet (2nd) - bet (1st)</code> : Showdown and the winner takes <code>+2</code></li> <li><code>pass (1st) - bet (2nd) - pass (1st)</code> : 2nd takes <code>+1</code></li> </ol>"},{"location":"kuhn_poker/#specs","title":"Specs","text":"Name Value Version <code>v1</code> Number of players <code>2</code> Number of actions <code>2</code> Observation shape <code>(7,)</code> Observation type <code>bool</code> Rewards <code>{-2, -1, +1, +2}</code>"},{"location":"kuhn_poker/#observation","title":"Observation","text":"Index Description <code>[0]</code> One if J in my hand <code>[1]</code> One if Q in my hand <code>[2]</code> One if K in my hand <code>[3]</code> One if 0 chip is bet by me <code>[4]</code> One if 1 chip is bet by me <code>[5]</code> One if 0 chip of the opponent <code>[6]</code> One if 1 chip of the opponent"},{"location":"kuhn_poker/#action","title":"Action","text":"<p>There are four distinct actions.</p> Action Index Bet 0 Pass 1"},{"location":"kuhn_poker/#rewards","title":"Rewards","text":"<p>The winner takes <code>+2</code> or <code>+1</code> depending on the game payoff. As Kuhn poker is zero-sum game, the loser takes <code>-2</code> or <code>-1</code> respectively.</p>"},{"location":"kuhn_poker/#termination","title":"Termination","text":"<p>Follows the rules above.</p>"},{"location":"kuhn_poker/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> <li><code>v1</code> : Simplify action space by Egiob in #1171 (v2.1.1) </li> </ul>"},{"location":"leduc_holdem/","title":"Leduc hold\u2019em","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"leduc_holdem/#description","title":"Description","text":"<p>Leduc hold\u2019em is a simplified poker proposed in [Souhty+05].</p>"},{"location":"leduc_holdem/#rules","title":"Rules","text":"<p>We quote the description in  [Souhty+05]:</p> <p>Leduc Hold \u2019Em. We have also constructed a smaller version of hold \u2019em, which seeks to retain the strategic elements of the large game while keeping the size of the game tractable. In Leduc hold \u2019em, the deck consists of two suits with three cards in each suit. There are two rounds. In the first round a single private card is dealt to each player. In the second round a single board card is revealed. There is a two-bet maximum, with raise amounts of 2 and 4 in the first and second round, respectively. Both players start the first round with 1 already in the pot.</p> <p></p> <p>Figure 1: An example decision tree for a single betting round in poker with a two-bet maximum. Leaf nodes with open boxes continue to the next round, while closed boxes end the hand.</p>"},{"location":"leduc_holdem/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>4</code> Observation shape <code>(7,)</code> Observation type <code>bool</code> Rewards <code>{-13, -12, ... 0, ..., 12, 13}</code>"},{"location":"leduc_holdem/#observation","title":"Observation","text":"Index Description <code>[0]</code> True if J in hand <code>[1]</code> True if Q in hand <code>[2]</code> True if K in hand <code>[3]</code> True if J is the public card <code>[4]</code> True if Q is the public card <code>[5]</code> True if K is the public card <code>[6:19]</code> represent my chip count (0, ..., 13) <code>[20:33]</code> represent opponent's chip count (0, ..., 13)"},{"location":"leduc_holdem/#action","title":"Action","text":"<p>There are four distinct actions.</p> Index Action 0 Call 1 Raise 2 Fold"},{"location":"leduc_holdem/#rewards","title":"Rewards","text":"<p>The reward is the payoff of the game.</p>"},{"location":"leduc_holdem/#termination","title":"Termination","text":"<p>Follows the rules above.</p>"},{"location":"leduc_holdem/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"leduc_holdem/#references","title":"References","text":"<ul> <li>Souhty+05(https://arxiv.org/abs/1207.1411) UAI2005</li> </ul>"},{"location":"minatar_asterix/","title":"MinAtar Asterix","text":""},{"location":"minatar_asterix/#usage","title":"Usage","text":"<p>Note that the MinAtar suite is provided as a separate extension for Pgx (<code>pgx-minatar</code>). Therefore, please run the following command additionaly to use the MinAtar suite in Pgx:</p> <pre><code>pip install pgx-minatar\n</code></pre> <p>Then, you can use the environment as follows:</p> <pre><code>import pgx\n\nenv = pgx.make(\"minatar-asterix\")\n</code></pre>"},{"location":"minatar_asterix/#description","title":"Description","text":"<p>MinAtar is originally proposed by <code>[Young&amp;Tian+19]</code>.  The Pgx implementation is intended to be the exact copy of the original MinAtar implementation in JAX. The Asterix environment is described as follows:</p> <p>The player can move freely along the 4 cardinal directions. Enemies and treasure spawn from the sides. A reward of +1 is given for picking up treasure. Termination occurs if the player makes contact with an enemy. Enemy and treasure direction are indicated by a trail channel. Difficulty is periodically increased by increasing the speed and spawn rate of enemies and treasure. </p> <p>github.com/kenjyoung/MinAtar - asterix.py</p>"},{"location":"minatar_asterix/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>1</code> Number of actions <code>5</code> Observation shape <code>(10, 10, 4)</code> Observation type <code>bool</code> Rewards <code>{0, 1}</code>"},{"location":"minatar_asterix/#observation","title":"Observation","text":"Index Channel <code>[:, :, 0]</code> Player <code>[:, :, 1]</code> Enemy <code>[:, :, 2]</code> Trail <code>[:, :, 3]</code> Gold"},{"location":"minatar_asterix/#action","title":"Action","text":"<p>No-op (0), left (1), right (2), up (3), or down (4).</p>"},{"location":"minatar_asterix/#version-history","title":"Version History","text":"<ul> <li><code>v1</code>: Specify rng key explicitly (API v2) by @sotetsuk in #1058 (v2.0.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"minatar_asterix/#training-example","title":"Training example","text":"<p>For MinAtar environments, we provide a PPO training example, which takes only 1 min to train on a single GPU.</p>"},{"location":"minatar_asterix/#baseline-models","title":"Baseline models","text":"<p>We provide a baseline model for the MinAtar Asterix environment, which reasonably plays the game.</p> <pre><code>model = pgx.make_baseline(\"minatar-asterix_v0\")\n\nlogits, value = model(state.observation)\n</code></pre> <p>We trained the model with PPO for 20M steps.  See wandb report for the details of the training.</p>"},{"location":"minatar_asterix/#reference","title":"Reference","text":"<ul> <li><code>[Young&amp;Tian+19]</code> \"Minatar: An atari-inspired testbed for thorough and reproducible reinforcement learning experiments\" arXiv:1903.03176</li> </ul>"},{"location":"minatar_asterix/#license","title":"License","text":"<p>Pgx is provided under the Apache 2.0 License, but the original MinAtar suite follows the GPL 3.0 License. Therefore, please note that the separated MinAtar extension for Pgx also adheres to the GPL 3.0 License.</p>"},{"location":"minatar_breakout/","title":"MinAtar Breakout","text":""},{"location":"minatar_breakout/#usage","title":"Usage","text":"<p>Note that the MinAtar suite is provided as a separate extension for Pgx (<code>pgx-minatar</code>). Therefore, please run the following command additionaly to use the MinAtar suite in Pgx:</p> <pre><code>pip install pgx-minatar\n</code></pre> <p>Then, you can use the environment as follows:</p> <pre><code>import pgx\n\nenv = pgx.make(\"minatar-breakout\")\n</code></pre>"},{"location":"minatar_breakout/#description","title":"Description","text":"<p>MinAtar is originally proposed by <code>[Young&amp;Tian+19]</code>.  The Pgx implementation is intended to be the exact copy of the original MinAtar implementation in JAX. The Breakout environment is described as follows:</p> <p>The player controls a paddle on the bottom of the screen and must bounce a ball tobreak 3 rows of bricks along the top of the screen. A reward of +1 is given for each brick broken by the ball.  When all bricks are cleared another 3 rows are added. The ball travels only along diagonals, when it hits the paddle it is bounced either to the left or right depending on the side of the paddle hit, when it hits a wall or brick it is reflected. Termination occurs when the ball hits the bottom of the screen. The balls direction is indicated by a trail channel.</p> <p>github.com/kenjyoung/MinAtar - breakout.py</p>"},{"location":"minatar_breakout/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>1</code> Number of actions <code>3</code> Observation shape <code>(10, 10, 4)</code> Observation type <code>bool</code> Rewards <code>{0, 1}</code>"},{"location":"minatar_breakout/#observation","title":"Observation","text":"Index Channel <code>[:, :, 0]</code> Paddle <code>[:, :, 1]</code> Ball <code>[:, :, 2]</code> Trail <code>[:, :, 3]</code> Brick"},{"location":"minatar_breakout/#action","title":"Action","text":"<p>No-op (0), left (1), or right (2).</p>"},{"location":"minatar_breakout/#version-history","title":"Version History","text":"<ul> <li><code>v1</code>: Specify rng key explicitly (API v2) by @sotetsuk in #1058 (v2.0.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"minatar_breakout/#training-example","title":"Training example","text":"<p>For MinAtar environments, we provide a PPO training example, which takes only 1 min to train on a single GPU.</p>"},{"location":"minatar_breakout/#baseline-models","title":"Baseline models","text":"<p>We provide a baseline model for the MinAtar Breakout environment, which reasonably plays the game.</p> <pre><code>model = pgx.make_baseline(\"minatar-breakout_v0\")\n\nlogits, value = model(state.observation)\n</code></pre> <p>We trained the model with PPO for 20M steps.  See wandb report for the details of the training.</p>"},{"location":"minatar_breakout/#reference","title":"Reference","text":"<ul> <li><code>[Young&amp;Tian+19]</code> \"Minatar: An atari-inspired testbed for thorough and reproducible reinforcement learning experiments\" arXiv:1903.03176</li> </ul>"},{"location":"minatar_breakout/#license","title":"License","text":"<p>Pgx is provided under the Apache 2.0 License, but the original MinAtar suite follows the GPL 3.0 License. Therefore, please note that the separated MinAtar extension for Pgx also adheres to the GPL 3.0 License.</p>"},{"location":"minatar_freeway/","title":"MinAtar Freeway","text":""},{"location":"minatar_freeway/#usage","title":"Usage","text":"<p>Note that the MinAtar suite is provided as a separate extension for Pgx (<code>pgx-minatar</code>). Therefore, please run the following command additionaly to use the MinAtar suite in Pgx:</p> <pre><code>pip install pgx-minatar\n</code></pre> <p>Then, you can use the environment as follows:</p> <pre><code>import pgx\n\nenv = pgx.make(\"minatar-freeway\")\n</code></pre>"},{"location":"minatar_freeway/#description","title":"Description","text":"<p>MinAtar is originally proposed by <code>[Young&amp;Tian+19]</code>.  The Pgx implementation is intended to be the exact copy of the original MinAtar implementation in JAX. The Freeway environment is described as follows:</p> <p>The player begins at the bottom of the screen and motion is restricted to traveling up and down. Player speed is also restricted such that the player can only move every 3 frames. A reward of +1 is given when the player reaches the top of the screen, at which point the player is returned to the bottom. Cars travel horizontally on the screen and teleport to the other side when the edge is reached. When hit by a car, the player is returned to the bottom of the screen. Car direction and speed is indicated by 5 trail channels, the location of the trail gives direction while the specific channel indicates how frequently the car moves (from once every frame to once every 5 frames). Each time the player successfully reaches the top of the screen, the car speeds are randomized. Termination occurs after 2500 frames have elapsed.</p> <p>github.com/kenjyoung/MinAtar - freeway.py</p>"},{"location":"minatar_freeway/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>1</code> Number of actions <code>3</code> Observation shape <code>(10, 10, 7)</code> Observation type <code>bool</code> Rewards <code>{0, 1}</code>"},{"location":"minatar_freeway/#observation","title":"Observation","text":"Index Channel <code>[:, :, 0]</code> Chicken <code>[:, :, 1]</code> Car <code>[:, :, 2]</code> Speed 1 <code>[:, :, 3]</code> Speed 2 <code>[:, :, 4]</code> Speed 3 <code>[:, :, 5]</code> Speed 4"},{"location":"minatar_freeway/#action","title":"Action","text":"<p>No-op (0), up (1), or down (2).</p>"},{"location":"minatar_freeway/#version-history","title":"Version History","text":"<ul> <li><code>v1</code>: Specify rng key explicitly (API v2) by @sotetsuk in #1058 (v2.0.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"minatar_freeway/#training-example","title":"Training example","text":"<p>For MinAtar environments, we provide a PPO training example, which takes only 1 min to train on a single GPU.</p>"},{"location":"minatar_freeway/#baseline-models","title":"Baseline models","text":"<p>We provide a baseline model for the MinAtar Freeway environment, which reasonably plays the game.</p> <pre><code>model = pgx.make_baseline(\"minatar-freeway_v0\")\n\nlogits, value = model(state.observation)\n</code></pre> <p>We trained the model with PPO for 20M steps.  See wandb report for the details of the training.</p>"},{"location":"minatar_freeway/#reference","title":"Reference","text":"<ul> <li><code>[Young&amp;Tian+19]</code> \"Minatar: An atari-inspired testbed for thorough and reproducible reinforcement learning experiments\" arXiv:1903.03176</li> </ul>"},{"location":"minatar_freeway/#license","title":"LICENSE","text":"<p>Pgx is provided under the Apache 2.0 License, but the original MinAtar suite follows the GPL 3.0 License. Therefore, please note that the separated MinAtar extension for Pgx also adheres to the GPL 3.0 License.</p>"},{"location":"minatar_seaquest/","title":"MinAtar Seaquest","text":""},{"location":"minatar_seaquest/#usage","title":"Usage","text":"<p>Note that the MinAtar suite is provided as a separate extension for Pgx (<code>pgx-minatar</code>). Therefore, please run the following command additionaly to use the MinAtar suite in Pgx:</p> <pre><code>pip install pgx-minatar\n</code></pre> <p>Then, you can use the environment as follows:</p> <pre><code>import pgx\n\nenv = pgx.make(\"minatar-seaquest\")\n</code></pre>"},{"location":"minatar_seaquest/#description","title":"Description","text":"<p>MinAtar is originally proposed by <code>[Young&amp;Tian+19]</code>.  The Pgx implementation is intended to be the exact copy of the original MinAtar implementation in JAX. The Seaquest environment is described as follows:</p> <p>The player controls a submarine consisting of two cells, front and back, to allow direction to be determined. The player can also fire bullets from the front of the submarine. Enemies consist of submarines and fish, distinguished by the fact that submarines shoot bullets and fish do not. A reward of +1 is given each time an enemy is struck by one of the player's bullets, at which point the enemy is also removed. There are also divers which the player can move onto to pick up, doing so increments a bar indicated by another channel along the bottom of the screen. The player also has a limited supply of oxygen indicated by another bar in another channel. Oxygen degrades over time, and is replenished whenever the player moves to the top of the screen as long as the player has at least one rescued diver on board. The player can carry a maximum of 6 divers. When surfacing with less than 6, one diver is removed. When surfacing with 6, all divers are removed and a reward is given for each active cell in the oxygen bar. Each time the player surfaces the difficulty is increased by increasing the spawn rate and movement speed of enemies. Termination occurs when the player is hit by an enemy fish, sub or bullet; or when oxygen reached 0; or when the player attempts to surface with no rescued divers. Enemy and diver directions are indicated by a trail channel active in their previous location to reduce partial observability.</p> <p>github.com/kenjyoung/MinAtar - seaquest.py</p>"},{"location":"minatar_seaquest/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>1</code> Number of actions <code>6</code> Observation shape <code>(10, 10, 10)</code> Observation type <code>bool</code> Rewards <code>{0, 1, ..., 10}</code>"},{"location":"minatar_seaquest/#observation","title":"Observation","text":"Index Channel <code>[:, :, 0]</code> Player submarine (front) <code>[:, :, 1]</code> Player submarine (back) <code>[:, :, 2]</code> Friendly bullet <code>[:, :, 3]</code> Trail <code>[:, :, 4]</code> Enemy bullet <code>[:, :, 5]</code> Enemy fish <code>[:, :, 6]</code> Enemy submarine <code>[:, :, 7]</code> Oxygen guage <code>[:, :, 8]</code> Diver guage <code>[:, :, 9]</code> Diver"},{"location":"minatar_seaquest/#action","title":"Action","text":"<p>No-op (0), up (1), down (2), left (3), right (4), or fire (5).</p>"},{"location":"minatar_seaquest/#version-history","title":"Version History","text":"<ul> <li><code>v1</code>: Specify rng key explicitly (API v2) by @sotetsuk in #1058 (v2.0.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"minatar_seaquest/#training-example","title":"Training example","text":"<p>For MinAtar environments, we provide a PPO training example, which takes only 1 min to train on a single GPU.</p>"},{"location":"minatar_seaquest/#baseline-models","title":"Baseline models","text":"<p>We provide a baseline model for the MinAtar Seaquest environment, which reasonably plays the game.</p> <pre><code>model = pgx.make_baseline(\"minatar-seaquest_v0\")\n\nlogits, value = model(state.observation)\n</code></pre> <p>We trained the model with PPO for 20M steps.  See wandb report for the details of the training.</p>"},{"location":"minatar_seaquest/#reference","title":"Reference","text":"<ul> <li><code>[Young&amp;Tian+19]</code> \"Minatar: An atari-inspired testbed for thorough and reproducible reinforcement learning experiments\" arXiv:1903.03176</li> </ul>"},{"location":"minatar_seaquest/#license","title":"LICENSE","text":"<p>Pgx is provided under the Apache 2.0 License, but the original MinAtar suite follows the GPL 3.0 License. Therefore, please note that the separated MinAtar extension for Pgx also adheres to the GPL 3.0 License.</p>"},{"location":"minatar_space_invaders/","title":"MinAtar Space Invaders","text":""},{"location":"minatar_space_invaders/#usage","title":"Usage","text":"<p>Note that the MinAtar suite is provided as a separate extension for Pgx (<code>pgx-minatar</code>). Therefore, please run the following command additionaly to use the MinAtar suite in Pgx:</p> <pre><code>pip install pgx-minatar\n</code></pre> <p>Then, you can use the environment as follows:</p> <pre><code>import pgx\n\nenv = pgx.make(\"minatar-space_invaders\")\n</code></pre>"},{"location":"minatar_space_invaders/#description","title":"Description","text":"<p>MinAtar is originally proposed by <code>[Young&amp;Tian+19]</code>.  The Pgx implementation is intended to be the exact copy of the original MinAtar implementation in JAX. The Space Invaders environment is described as follows:</p> <p>The player controls a cannon at the bottom of the screen and can shoot bullets upward at a cluster of aliens above. The aliens move across the screen until one of them hits the edge, at which point they all move down and switch directions. The current alien direction is indicated by 2 channels (one for left and one for right) one of which is active at the location of each alien. A reward of +1 is given each time an alien is shot, and that alien is also removed. The aliens will also shoot bullets back at the player. When few aliens are left, alien speed will begin to increase. When only one alien is left, it will move at one cell per frame. When a wave of aliens is fully cleared a new one will spawn which moves at a slightly faster speed than the last. Termination occurs when an alien or bullet hits the player.</p> <p>github.com/kenjyoung/MinAtar - space_invaders.py</p>"},{"location":"minatar_space_invaders/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>1</code> Number of actions <code>4</code> Observation shape <code>(10, 10, 6)</code> Observation type <code>bool</code> Rewards <code>{0, 1}</code>"},{"location":"minatar_space_invaders/#observation","title":"Observation","text":"Index Channel <code>[:, :, 0]</code> Cannon <code>[:, :, 1]</code> Alien <code>[:, :, 2]</code> Alien left <code>[:, :, 3]</code> Alien right <code>[:, :, 4]</code> Friendly bullet <code>[:, :, 5]</code> Enemy bullet"},{"location":"minatar_space_invaders/#action","title":"Action","text":"<p>No op (0), left (1), right (2), or fire (3).</p>"},{"location":"minatar_space_invaders/#version-history","title":"Version History","text":"<ul> <li><code>v1</code>: Specify rng key explicitly (API v2) by @sotetsuk in #1058 (v2.0.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"minatar_space_invaders/#training-example","title":"Training example","text":"<p>For MinAtar environments, we provide a PPO training example, which takes only 1 min to train on a single GPU.</p>"},{"location":"minatar_space_invaders/#baseline-models","title":"Baseline models","text":"<p>We provide a baseline model for the MinAtar Space Invaders environment, which reasonably plays the game.</p> <pre><code>model = pgx.make_baseline(\"minatar-space_invaders_v0\")\n\nlogits, value = model(state.observation)\n</code></pre> <p>We trained the model with PPO for 20M steps.  See wandb report for the details of the training.</p>"},{"location":"minatar_space_invaders/#reference","title":"Reference","text":"<ul> <li><code>[Young&amp;Tian+19]</code> \"Minatar: An atari-inspired testbed for thorough and reproducible reinforcement learning experiments\" arXiv:1903.03176</li> </ul>"},{"location":"minatar_space_invaders/#license","title":"LICENSE","text":"<p>Pgx is provided under the Apache 2.0 License, but the original MinAtar suite follows the GPL 3.0 License. Therefore, please note that the separated MinAtar extension for Pgx also adheres to the GPL 3.0 License.</p>"},{"location":"othello/","title":"Othello","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"othello/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"othello\")\n</code></pre> <p>or you can directly load <code>Othello</code> class</p> <pre><code>from pgx.othello import Othello\n\nenv = Othello()\n</code></pre>"},{"location":"othello/#description","title":"Description","text":"<p>Othello, or differing in not having a defined starting position, Reversi, is a two-player zero-sum and perfect information abstract strategy board game, usually played on a board with 8 rows and 8 columns and a set of light and a dark turnable pieces for each side. The player's goal is to have a majority of their colored pieces showing at the end of the game, turning over as many of their opponent's pieces as possible. The dark player makes the first move from the starting position, alternating with the light player. Each player has to place a piece on the board such that there exists at least one straight (horizontal, vertical, or diagonal) occupied line of opponent pieces between the new piece and another own piece. After placing the piece, the side turns over (flips, captures) all opponent pieces lying on any straight lines between the new piece and any anchoring own pieces.</p> <p>Chess Programming Wiki</p>"},{"location":"othello/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>65 (= 8 x 8 + 1)</code> Observation shape <code>(8, 8, 2)</code> Observation type <code>bool</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"othello/#observation","title":"Observation","text":"Index Description <code>[:, :, 0]</code> represents <code>(8, 8)</code> squares colored by the current player <code>[:, :, 1]</code> represents <code>(8, 8)</code> squares colored by the opponent player of current player"},{"location":"othello/#action","title":"Action","text":"<p>Each action (<code>{0, ..., 63}</code>) represents the square index to be filled. The last <code>64</code>-th action represents pass action.</p>"},{"location":"othello/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"othello/#termination","title":"Termination","text":"<p>Termination happens when all <code>64 (= 8 x 8)</code> playable squares are filled.</p>"},{"location":"othello/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"othello/#baseline-models","title":"Baseline models","text":"<p>Pgx offers a baseline model for Othello. Users can use it for an anchor opponent in evaluation. See our paper for more details. See this colab for how to use it.</p> Model ID Description <code>othello_v0</code> See our paper for the training details."},{"location":"play2048/","title":"2048","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"play2048/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"2048\")\n</code></pre> <p>or you can directly load <code>Play2048</code> class</p> <pre><code>from pgx.paly2048 import Play2048\n\nenv = Play2048()\n</code></pre>"},{"location":"play2048/#description","title":"Description","text":"<p>2048 ...</p> <p>Wikipedia</p>"},{"location":"play2048/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>1</code> Number of actions <code>4</code> Observation shape <code>(4, 4, 31)</code> Observation type <code>bool</code> Rewards <code>{0, 2, 4, ...}</code>"},{"location":"play2048/#observation","title":"Observation","text":"<p>Our obseervation design basically follows <code>[Antonoglou+22]</code>:</p> <p>In our 2048 experiments we used a binary representation of the observation as an input to our model. Specifically, the 4 \u00d7 4 board was flattened into a single vector of size 16, and a binary representation of 31 bits for each number was obtained, for a total size of 496 numbers.</p> <p>However, instaead of <code>496</code>-d flat vector, we employ <code>(4, 4, 31)</code> vector. </p> Index Description <code>[i, j, b]</code> represents that square <code>(i, j)</code> has a tile of <code>2 ^ b</code> if <code>b &gt; 0</code>"},{"location":"play2048/#action","title":"Action","text":"<p>Each action corresnponds to <code>0 (left)</code>, <code>1 (up)</code>, <code>2 (right)</code>, <code>3 (down)</code>.</p>"},{"location":"play2048/#rewards","title":"Rewards","text":"<p>Sum of merged tiles.</p>"},{"location":"play2048/#termination","title":"Termination","text":"<p>If all squares are filled with tiles and no legal actions are available, the game terminates.</p>"},{"location":"play2048/#version-history","title":"Version History","text":"<ul> <li><code>v2</code>: Two updates (v2.0.0)</li> <li>Fix <code>legal_action_mask</code> @sotetsuk in #1049</li> <li>Specify rng key explicitly (API v2) by @sotetsuk in #1058 </li> <li><code>v1</code> : Fix reward overflow bug by @sotetsuk in #1034 (v1.4.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"play2048/#reference","title":"Reference","text":"<ol> <li><code>[Antonoglou+22]</code> \"Planning in Stochastic Environments with a Learned Modell\", ICLR</li> </ol>"},{"location":"shogi/","title":"Shogi","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"shogi/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"shogi\")\n</code></pre> <p>or you can directly load <code>Shogi</code> class</p> <pre><code>from pgx.shogi import Shogi\n\nenv = Shogi()\n</code></pre>"},{"location":"shogi/#description","title":"Description","text":"<p>TBA</p>"},{"location":"shogi/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>2187</code> Observation shape <code>(9, 9, 119)</code> Observation type <code>bool</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"shogi/#observation","title":"Observation","text":"<p>We follow the observation design of dlshogi, an open-source shogi AI.  Ther original dlshogi implementations are here. Pgx implementation has <code>[9, 9, 119]</code> shape and <code>[:, :, x]</code> denotes:</p> <code>x</code> Description <code>0:14</code> Where my piece <code>x</code> exists <code>14:28</code> Where my pieces <code>x</code> are attacking <code>28:31</code> Where the number of my attacking pieces are <code>&gt;= 1,2,3</code> respectively <code>31:45</code> Where opponent's piece <code>x</code> exists <code>45:59</code> Where opponent's pieces <code>x</code> are attacking <code>59:62</code> Where the number of opponent's attacking pieces are <code>&gt;= 1,2,3</code> respectively <p>The following planes are all ones ore zeros</p> <code>x</code> Description <code>62:70</code> My hand has <code>&gt;= 1, ..., 8</code> Pawn <code>70:74</code> My hand has <code>&gt;= 1, 2, 3, 4</code> Lance <code>74:78</code> My hand has <code>&gt;= 1, 2, 3, 4</code> Knight <code>78:82</code> My hand has <code>&gt;= 1, 2, 3, 4</code> Silver <code>82:86</code> My hand has <code>&gt;= 1, 2, 3, 4</code> Gold <code>86:88</code> My hand has <code>&gt;= 1, 2</code> Bishop <code>88:90</code> My hand has <code>&gt;= 1, 2</code> Rook <code>90:98</code> Oppnent's hand has <code>&gt;= 1, ..., 8</code> Pawn <code>98:102</code> Oppnent's hand has <code>&gt;= 1, 2, 3, 4</code> Lance <code>102:106</code> Oppnent's hand has <code>&gt;= 1, 2, 3, 4</code> Knight <code>106:110</code> Oppnent's hand has <code>&gt;= 1, 2, 3, 4</code> Silver <code>110:114</code> Oppnent's hand has <code>&gt;= 1, 2, 3, 4</code> Gold <code>114:116</code> Oppnent's hand has <code>&gt;= 1, 2</code> Bishop <code>116:118</code> Oppnent's hand has <code>&gt;= 1, 2</code> Rook <code>118</code> Ones if checked <p>Note that piece ids are</p> Piece Id \u6b69\u3000 <code>PAWN</code> <code>0</code> \u9999\u3000 <code>LANCE</code> <code>1</code> \u6842\u3000 <code>KNIGHT</code> <code>2</code> \u9280\u3000 <code>SILVER</code> <code>3</code> \u89d2\u3000 <code>BISHOP</code> <code>4</code> \u98db\u3000 <code>ROOK</code> <code>5</code> \u91d1\u3000 <code>GOLD</code> <code>6</code> \u7389\u3000 <code>KING</code> <code>7</code> \u3068\u3000 <code>PRO_PAWN</code> <code>8</code> \u6210\u9999 <code>PRO_LANCE</code> <code>9</code> \u6210\u6842 <code>PRO_KNIGHT</code> <code>10</code> \u6210\u9280 <code>PRO_SILVER</code> <code>11</code> \u99ac\u3000 <code>HORSE</code> <code>12</code> \u9f8d\u3000 <code>DRAGON</code> <code>13</code>"},{"location":"shogi/#action","title":"Action","text":"<p>The design of action also follows that of dlshogi. There are <code>2187 = 81 x 27</code> distinct actions. The action can be decomposed into </p> <ul> <li><code>direction</code> from which the piece moves and</li> <li><code>destination</code> to which the piece moves</li> </ul> <p>by <code>direction, destination = action // 81, action % 81</code>. The <code>direction</code> is encoded by</p> id direction 0 Up 1 Up left 2 Up right 3 Left 4 Right 5 Down 6 Down left 7 Down right 8 Up2 left 9 Up2 right 10 Promote + Up 11 Promote + Up left 12 Promote + Up right 13 Promote + Left 14 Promote + Right 15 Promote + Down 16 Promote + Down left 17 Promote + Down right 18 Promote + Up2 left 19 Promote + Up2 right 20 Drop Pawn 21 Drop Lance 22 Drop Knight 23 Drop Silver 24 Drop Bishop 25 Drop Rook 26 Drop Gold"},{"location":"shogi/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"shogi/#termination","title":"Termination","text":"<p>Termination occurs when </p> <ol> <li>either player checkmates the opponent, or</li> <li><code>512</code> steps are elapsed (from AlphaZero <code>[Silver+18]</code>)</li> </ol> <p>Fourfold repetition is not implemented in <code>v0</code>.</p>"},{"location":"shogi/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"sparrow_mahjong/","title":"Sparrow mahjong","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"sparrow_mahjong/#description","title":"Description","text":"<p>Sparrow Mahjong (\u3059\u305a\u3081\u96c0) is a simplified version of Japanese Mahjong (Riichi Mahjong). It was developed for those unfamiliar with Mahjong, and requires similar strategic thinking to standard Japanese Mahjong.</p>"},{"location":"sparrow_mahjong/#rules-of-sparrow-mahjong","title":"Rules of Sparrow Mahjong","text":"<p>The original rules of Sparrow Mahjong (\u3059\u305a\u3081\u96c0) are summarized as follows:</p> <ul> <li>For 2-6 players</li> <li>11 types of tiles (44 tiles): <ul> <li>1-9 of bamboo, 1-9 of characters (x 4)</li> <li>red dragon (x 4)</li> <li>green dragon (x 4)</li> </ul> </li> <li>Basically 5 tiles in hand, 6 tiles after drawing</li> <li>2 sets of sequences or triplets to complete hand</li> <li>No chi (chow), pon (pong/pung), kan (kong), or riichi</li> <li>Dora is the same as the revealed tile</li> <li>Red doras: <ul> <li>all red doragons are red dora (4 tiles)</li> <li>all green doragons are NOT dora</li> <li>one red dora for each banboo tile type (9 tiles)</li> </ul> </li> <li>Furiten: you cannot ron with a tile you have discarded, but you can ron with other tiles</li> </ul>"},{"location":"sparrow_mahjong/#specifications-in-pgx","title":"Specifications in Pgx","text":"<p>Pgx implementation is simplified as follows:</p> <ul> <li>Only for 3 players</li> <li>Actions are only for discarding tiles (11 discrete actions)</li> <li>If players can win, they automatically win</li> <li>Players always keep red doras in their hands (i.e., red doras are not discarded if they have same but non-dora tiles)</li> <li>No Heavenly hand (Tenhou/\u5929\u548c) to avoid the game ends without any action from players</li> </ul>"},{"location":"sparrow_mahjong/#specs","title":"Specs","text":"Name Value Version <code>v1</code> Number of players <code>3</code> Number of actions <code>11</code> Observation shape <code>(11, 15)</code> Observation type <code>bool</code> Rewards <code>[-1, 1]</code>"},{"location":"sparrow_mahjong/#observation","title":"Observation","text":"<p>There are 15 planes in the observation and each plane consists of 11 tiles.</p> Planes Description 4 P1 hand 1 Red dora in P1 hand 1 Dora 1 All discarded tiles by P1 1 All discarded tiles by P2 1 All discarded tiles by P3 3 Discarded tiles in the last 3 steps by P2 3 Discarded tiles in the last 3 steps by P3"},{"location":"sparrow_mahjong/#action","title":"Action","text":"<p>Tile to discard.</p>"},{"location":"sparrow_mahjong/#rewards","title":"Rewards","text":"<p>Game payoff normalized to <code>[-1, 1]</code></p>"},{"location":"sparrow_mahjong/#termination","title":"Termination","text":"<p>Terminates when either player wins or the wall becomes empty.</p>"},{"location":"sparrow_mahjong/#version-history","title":"Version History","text":"<ul> <li><code>v1</code> : Change observation shape from <code>(15, 11)</code> to <code>(11, 15)</code> by @sotetsuk in #1010 (v1.3.0)</li> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"},{"location":"tic_tac_toe/","title":"Tic-tac-toe","text":"darklight <p><p> </p></p> <p><p> </p></p>"},{"location":"tic_tac_toe/#usage","title":"Usage","text":"<pre><code>import pgx\n\nenv = pgx.make(\"tic_tac_toe\")\n</code></pre> <p>or you can directly load <code>TicTacToe</code> class</p> <pre><code>from pgx.tic_tac_toe import TicTacToe\n\nenv = TicTacToe()\n</code></pre>"},{"location":"tic_tac_toe/#description","title":"Description","text":"<p>Tic-tac-toe is a paper-and-pencil game for two players who take turns marking the spaces in a three-by-three grid with X or O. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row is the winner. </p> <p>Wikipedia</p>"},{"location":"tic_tac_toe/#specs","title":"Specs","text":"Name Value Version <code>v0</code> Number of players <code>2</code> Number of actions <code>9</code> Observation shape <code>(3, 3, 2)</code> Observation type <code>bool</code> Rewards <code>{-1, 0, 1}</code>"},{"location":"tic_tac_toe/#observation","title":"Observation","text":"Index Description <code>[:, :, 0]</code> represents <code>(3, 3)</code> squares filled by the current player <code>[:, :, 1]</code> represents <code>(3, 3)</code> squares filled by the opponent player of current player"},{"location":"tic_tac_toe/#action","title":"Action","text":"<p>Each action represents the square index to be filled.</p>"},{"location":"tic_tac_toe/#rewards","title":"Rewards","text":"<p>Non-zero rewards are given only at the terminal states. The reward at terminal state is described in this table:</p> Reward Win <code>+1</code> Lose <code>-1</code> Draw <code>0</code>"},{"location":"tic_tac_toe/#termination","title":"Termination","text":"<p>Termination happens when </p> <ol> <li>either one player places three of their symbols in a row (horizontally, vertically, or diagonally), or </li> <li>all nine squares are filled.</li> </ol>"},{"location":"tic_tac_toe/#version-history","title":"Version History","text":"<ul> <li><code>v0</code> : Initial release (v1.0.0)</li> </ul>"}]}