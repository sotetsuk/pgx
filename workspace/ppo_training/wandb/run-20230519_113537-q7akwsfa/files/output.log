
training of backgammon
(1, 34)
{'value_loss': 8.652365684509277, 'loss_actor': -0.02006351388990879, 'entropy': 5.075316429138184, 'eval_vs_previous_policy': -3.0, 'steps': 8192}
{'value_loss': 7.984470844268799, 'loss_actor': -0.015960855409502983, 'entropy': 5.064560890197754, 'eval_vs_previous_policy': -3.0, 'steps': 16384}
{'value_loss': 7.4015350341796875, 'loss_actor': -0.01632697321474552, 'entropy': 5.055344581604004, 'eval_vs_previous_policy': -3.0, 'steps': 24576}
{'value_loss': 6.8789286613464355, 'loss_actor': -0.01743832789361477, 'entropy': 5.044846534729004, 'eval_vs_previous_policy': -3.0, 'steps': 32768}
{'value_loss': 6.531229496002197, 'loss_actor': -0.01806245930492878, 'entropy': 5.037991523742676, 'eval_vs_previous_policy': -3.0, 'steps': 40960}
{'value_loss': 5.942690849304199, 'loss_actor': -0.017948364838957787, 'entropy': 5.0208306312561035, 'eval_vs_previous_policy': -3.0, 'steps': 49152}
{'value_loss': 5.720649719238281, 'loss_actor': -0.021532313898205757, 'entropy': 5.009157180786133, 'eval_vs_previous_policy': -3.0, 'steps': 57344}
{'value_loss': 5.298336029052734, 'loss_actor': -0.02002357877790928, 'entropy': 4.999566078186035, 'eval_vs_previous_policy': -3.0, 'steps': 65536}
{'value_loss': 5.101338863372803, 'loss_actor': -0.020152103155851364, 'entropy': 4.986495018005371, 'eval_vs_previous_policy': -3.0, 'steps': 73728}
{'value_loss': 4.76996374130249, 'loss_actor': -0.01930527202785015, 'entropy': 4.972171306610107, 'eval_vs_previous_policy': -3.0, 'steps': 81920}
{'value_loss': 4.605992794036865, 'loss_actor': -0.02288915030658245, 'entropy': 4.960069179534912, 'eval_vs_previous_policy': -3.0, 'steps': 90112}
{'value_loss': 4.351041793823242, 'loss_actor': -0.02449440397322178, 'entropy': 4.9501872062683105, 'eval_vs_previous_policy': -3.0, 'steps': 98304}
{'value_loss': 4.312860488891602, 'loss_actor': -0.025116553530097008, 'entropy': 4.940916061401367, 'eval_vs_previous_policy': -3.0, 'steps': 106496}
{'value_loss': 4.123523235321045, 'loss_actor': -0.027755405753850937, 'entropy': 4.921175003051758, 'eval_vs_previous_policy': -3.0, 'steps': 114688}
{'value_loss': 4.043284893035889, 'loss_actor': -0.02922794781625271, 'entropy': 4.904429912567139, 'eval_vs_previous_policy': -3.0, 'steps': 122880}
{'value_loss': 3.9970922470092773, 'loss_actor': -0.03401176631450653, 'entropy': 4.891866683959961, 'eval_vs_previous_policy': -3.0, 'steps': 131072}
{'value_loss': 3.9462926387786865, 'loss_actor': -0.034017641097307205, 'entropy': 4.875344753265381, 'eval_vs_previous_policy': -3.0, 'steps': 139264}
{'value_loss': 3.9358060359954834, 'loss_actor': -0.03427061066031456, 'entropy': 4.868379592895508, 'eval_vs_previous_policy': -3.0, 'steps': 147456}
{'value_loss': 3.889727830886841, 'loss_actor': -0.03452306240797043, 'entropy': 4.857614517211914, 'eval_vs_previous_policy': -3.0, 'steps': 155648}
{'value_loss': 3.837095022201538, 'loss_actor': -0.03536127880215645, 'entropy': 4.846780776977539, 'eval_vs_previous_policy': -3.0, 'steps': 163840}
{'value_loss': 3.8378615379333496, 'loss_actor': -0.03762416914105415, 'entropy': 4.822689533233643, 'eval_vs_previous_policy': -3.0, 'steps': 172032}
{'value_loss': 3.7338860034942627, 'loss_actor': -0.03690807893872261, 'entropy': 4.797646999359131, 'eval_vs_previous_policy': -3.0, 'steps': 180224}
{'value_loss': 3.682084798812866, 'loss_actor': -0.03826957195997238, 'entropy': 4.7608160972595215, 'eval_vs_previous_policy': -3.0, 'steps': 188416}
{'value_loss': 3.6244797706604004, 'loss_actor': -0.038590338081121445, 'entropy': 4.735184192657471, 'eval_vs_previous_policy': -3.0, 'steps': 196608}
{'value_loss': 3.5217959880828857, 'loss_actor': -0.03916209563612938, 'entropy': 4.702500343322754, 'eval_vs_previous_policy': -3.0, 'steps': 204800}
{'value_loss': 3.4598183631896973, 'loss_actor': -0.03999917209148407, 'entropy': 4.667218208312988, 'eval_vs_previous_policy': -3.0, 'steps': 212992}
{'value_loss': 3.4539103507995605, 'loss_actor': -0.040361955761909485, 'entropy': 4.624621868133545, 'eval_vs_previous_policy': -3.0, 'steps': 221184}
{'value_loss': 3.3816356658935547, 'loss_actor': -0.043091971427202225, 'entropy': 4.575685977935791, 'eval_vs_previous_policy': -3.0, 'steps': 229376}
{'value_loss': 3.404928207397461, 'loss_actor': -0.048225078731775284, 'entropy': 4.494655132293701, 'eval_vs_previous_policy': -3.0, 'steps': 237568}
{'value_loss': 3.414346694946289, 'loss_actor': -0.050478074699640274, 'entropy': 4.391791820526123, 'eval_vs_previous_policy': -3.0, 'steps': 245760}
{'value_loss': 3.3868696689605713, 'loss_actor': -0.04642106965184212, 'entropy': 4.269461631774902, 'eval_vs_previous_policy': -3.0, 'steps': 253952}
{'value_loss': 3.3414571285247803, 'loss_actor': -0.049884993582963943, 'entropy': 4.14626407623291, 'eval_vs_previous_policy': -3.0, 'steps': 262144}
{'value_loss': 3.363628625869751, 'loss_actor': -0.048408884555101395, 'entropy': 3.9722723960876465, 'eval_vs_previous_policy': -3.0, 'steps': 270336}
{'value_loss': 3.388317584991455, 'loss_actor': -0.04107152670621872, 'entropy': 3.803394317626953, 'eval_vs_previous_policy': -3.0, 'steps': 278528}
{'value_loss': 3.3034863471984863, 'loss_actor': -0.03832376375794411, 'entropy': 3.6023776531219482, 'eval_vs_previous_policy': -3.0, 'steps': 286720}
{'value_loss': 3.3039565086364746, 'loss_actor': -0.03509807586669922, 'entropy': 3.498708963394165, 'eval_vs_previous_policy': -3.0, 'steps': 294912}
{'value_loss': 3.2218496799468994, 'loss_actor': -0.0331774465739727, 'entropy': 3.420297622680664, 'eval_vs_previous_policy': -3.0, 'steps': 303104}
{'value_loss': 3.247124433517456, 'loss_actor': -0.030550861731171608, 'entropy': 3.311976432800293, 'eval_vs_previous_policy': -3.0, 'steps': 311296}
{'value_loss': 3.1634156703948975, 'loss_actor': -0.028911959379911423, 'entropy': 3.241150379180908, 'eval_vs_previous_policy': -3.0, 'steps': 319488}
{'value_loss': 2.962010383605957, 'loss_actor': -0.02882031723856926, 'entropy': 3.166231155395508, 'eval_vs_previous_policy': -3.0, 'steps': 327680}
{'value_loss': 2.9497838020324707, 'loss_actor': -0.027844877913594246, 'entropy': 3.1382696628570557, 'eval_vs_previous_policy': -3.0, 'steps': 335872}
{'value_loss': 2.855478525161743, 'loss_actor': -0.027979984879493713, 'entropy': 3.1756768226623535, 'eval_vs_previous_policy': -3.0, 'steps': 344064}
{'value_loss': 2.8150923252105713, 'loss_actor': -0.025497179478406906, 'entropy': 3.0587806701660156, 'eval_vs_previous_policy': -3.0, 'steps': 352256}
{'value_loss': 2.715303897857666, 'loss_actor': -0.029822755604982376, 'entropy': 3.013413667678833, 'eval_vs_previous_policy': -3.0, 'steps': 360448}
{'value_loss': 2.631195068359375, 'loss_actor': -0.02470399998128414, 'entropy': 2.976886034011841, 'eval_vs_previous_policy': -3.0, 'steps': 368640}
{'value_loss': 2.52675199508667, 'loss_actor': -0.028113050386309624, 'entropy': 2.9293181896209717, 'eval_vs_previous_policy': -3.0, 'steps': 376832}
{'value_loss': 2.504255533218384, 'loss_actor': -0.031989701092243195, 'entropy': 2.9297678470611572, 'eval_vs_previous_policy': -3.0, 'steps': 385024}
{'value_loss': 2.381993532180786, 'loss_actor': -0.030621547251939774, 'entropy': 2.8816769123077393, 'eval_vs_previous_policy': -3.0, 'steps': 393216}
{'value_loss': 2.4287991523742676, 'loss_actor': -0.029482318088412285, 'entropy': 2.897076368331909, 'eval_vs_previous_policy': -3.0, 'steps': 401408}
{'value_loss': 2.339111804962158, 'loss_actor': -0.032877642661333084, 'entropy': 2.9377031326293945, 'eval_vs_previous_policy': -3.0, 'steps': 409600}
{'value_loss': 2.4066977500915527, 'loss_actor': -0.027812141925096512, 'entropy': 2.90409517288208, 'eval_vs_previous_policy': -3.0, 'steps': 417792}
{'value_loss': 2.387517213821411, 'loss_actor': -0.03215831518173218, 'entropy': 2.9002487659454346, 'eval_vs_previous_policy': -3.0, 'steps': 425984}
{'value_loss': 2.4441325664520264, 'loss_actor': -0.03490377217531204, 'entropy': 2.896122932434082, 'eval_vs_previous_policy': -3.0, 'steps': 434176}
{'value_loss': 2.3628787994384766, 'loss_actor': -0.032483309507369995, 'entropy': 2.882441282272339, 'eval_vs_previous_policy': -3.0, 'steps': 442368}
{'value_loss': 2.2764382362365723, 'loss_actor': -0.0347815565764904, 'entropy': 2.859680652618408, 'eval_vs_previous_policy': -3.0, 'steps': 450560}
{'value_loss': 2.3089704513549805, 'loss_actor': -0.03298567235469818, 'entropy': 2.7690670490264893, 'eval_vs_previous_policy': -3.0, 'steps': 458752}
{'value_loss': 2.3786444664001465, 'loss_actor': -0.03162132203578949, 'entropy': 2.742551565170288, 'eval_vs_previous_policy': -3.0, 'steps': 466944}
{'value_loss': 2.2871310710906982, 'loss_actor': -0.03254776820540428, 'entropy': 2.7130210399627686, 'eval_vs_previous_policy': -3.0, 'steps': 475136}
{'value_loss': 2.183745861053467, 'loss_actor': -0.03317996487021446, 'entropy': 2.7009782791137695, 'eval_vs_previous_policy': -3.0, 'steps': 483328}
{'value_loss': 2.2058141231536865, 'loss_actor': -0.03331702575087547, 'entropy': 2.743321180343628, 'eval_vs_previous_policy': -3.0, 'steps': 491520}
{'value_loss': 2.273606538772583, 'loss_actor': -0.03394584730267525, 'entropy': 2.74910044670105, 'eval_vs_previous_policy': -3.0, 'steps': 499712}
{'value_loss': 2.1811556816101074, 'loss_actor': -0.03382387384772301, 'entropy': 2.698331594467163, 'eval_vs_previous_policy': -3.0, 'steps': 507904}
Traceback (most recent call last):
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 343, in <module>
    out = train(config, rng)
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 306, in train
    eval_R = evaluate(runner_state[0], old_train_state, network, env, rng, config["NUM_ENVS"])
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 252, in evaluate
    state = step(state, action)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/pjit.py", line 208, in cache_miss
    outs, out_flat, out_tree, args_flat = _python_pjit_helper(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/pjit.py", line 155, in _python_pjit_helper
    out_flat = pjit_p.bind(*args_flat, **params)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/core.py", line 2633, in bind
    return self.bind_with_trace(top_trace, args, params)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/core.py", line 383, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/core.py", line 790, in process_primitive
    return primitive.impl(*tracers, **params)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/pjit.py", line 1088, in _pjit_call_impl
    always_lower=False, lowering_platform=None).compile()
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py", line 2313, in compile
    executable = UnloadedMeshExecutable.from_hlo(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py", line 2633, in from_hlo
    xla_executable, compile_options = _cached_compilation(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py", line 2551, in _cached_compilation
    xla_executable = dispatch.compile_or_get_cached(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/dispatch.py", line 495, in compile_or_get_cached
    return backend_compile(backend, computation, compile_options,
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/profiler.py", line 314, in wrapper
    return func(*args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/dispatch.py", line 463, in backend_compile
    return backend.compile(built_c, compile_options=options)
KeyboardInterrupt