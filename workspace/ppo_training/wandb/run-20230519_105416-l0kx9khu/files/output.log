
training of backgammon
Traceback (most recent call last):
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 344, in <module>
    out = train(config, rng)
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 276, in train
    network_params = network.init(_rng, init_x)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 1640, in init
    _, v_out = self.init_with_output(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 1545, in init_with_output
    return init_with_output(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/core/scope.py", line 965, in wrapper
    return apply(fn, mutable=mutable, flags=init_flags)({}, *args, rngs=rngs,
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/core/scope.py", line 933, in wrapper
    y = fn(root, *args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 2121, in scope_fn
    return fn(module.clone(parent=scope), *args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 50, in __call__
    x = nn.Conv(features=32, kernel_size=(2, 2))(x)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/linear.py", line 449, in __call__
    y = self.conv_general_dilated(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/lax/convolution.py", line 146, in conv_general_dilated
    padding = lax.padtype_to_pads(
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/lax/lax.py", line 4499, in padtype_to_pads
    out_shape = _ceil_divide(in_shape, window_strides)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/jax/_src/lax/lax.py", line 4474, in _ceil_divide
    return -np.floor_divide(np.negative(x1), x2)
jax._src.traceback_util.UnfilteredStackTrace: ValueError: operands could not be broadcast together with shapes (0,) (2,)
The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.
--------------------
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 344, in <module>
    out = train(config, rng)
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 276, in train
    network_params = network.init(_rng, init_x)
  File "/root/src/pgx/pgx/workspace/backgammon_trainig/ppo.py", line 50, in __call__
    x = nn.Conv(features=32, kernel_size=(2, 2))(x)
  File "/root/.pyenv/versions/3.10.0/lib/python3.10/site-packages/flax/linen/linear.py", line 449, in __call__
    y = self.conv_general_dilated(
ValueError: operands could not be broadcast together with shapes (0,) (2,)