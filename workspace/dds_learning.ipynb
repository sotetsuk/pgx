{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sotetsuk/pgx/blob/harukaki%2Ffeat%2Fbridge_dds_learning/workspace/dds_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VaHlMdX7XEB",
        "outputId": "09738a1e-04d5-4e8b-dd20-7a15c50cc5f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5BlGJTSwpez",
        "outputId": "c8a046f1-0d83-4bc6-dbdb-92409669f94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chex>=0.1.5\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from optax) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.8/dist-packages (from optax) (0.3.25)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from optax) (1.3.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.5 optax-0.1.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.8-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=685d28079fe48adc7cc75c30c0dd2b87b650d5c460b47c035bfaf3380a341a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, urllib3, smmap, setproctitle, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.30 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.12.1 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.8\n"
          ]
        }
      ],
      "source": [
        "!pip install optax\n",
        "!pip install tqdm\n",
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "92QVPdukanTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33914053-3c2b-41a6-b55a-4ed920ab1f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GhIOnXxULLmI"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from contextlib import closing\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "import time\n",
        "import tqdm\n",
        "import os\n",
        "import wandb\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "wandb.init(project = \"dds_learning\",\n",
        "           config = {\n",
        "                  \"TRAIN_SAMPLE_NUM\" : 2000000,\n",
        "                  \"TEST_SAMPLE_NUM\" : 500000,\n",
        "                  \"EPOCHS\" : 10,\n",
        "                  \"BATCH_SIZE\" : 1000,\n",
        "                  \"HIDDEN_LAYER_SIZE\" : 1024,\n",
        "                  \"LAYER_NUM\" : 5,\n",
        "                  \"lr\" : 1e-4}\n",
        "           )\n",
        "config = wandb.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "zq5n8R18VmMC",
        "outputId": "03ec69b9-1339-4a54-e5f1-9e26987f486a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhrkkt1213\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230112_000629-uxw6qbbn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hrkkt1213/dds_learning/runs/uxw6qbbn\" target=\"_blank\">fast-cloud-17</a></strong> to <a href=\"https://wandb.ai/hrkkt1213/dds_learning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/hrkkt1213/dds_learning\" target=\"_blank\">https://wandb.ai/hrkkt1213/dds_learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/hrkkt1213/dds_learning/runs/uxw6qbbn\" target=\"_blank\">https://wandb.ai/hrkkt1213/dds_learning/runs/uxw6qbbn</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PPNzGbicSvRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332db9c5-f7e2-48e4-f9ff-95f471374720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "files exist\n",
            "load files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000000, 208)\n",
            "(2000000, 20)\n",
            "(500000, 208)\n",
            "(500000, 20)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def pbn_to_bool(pbn):\n",
        "  deal = [0] * 208\n",
        "  suit = 0\n",
        "  for i in range(9, 76):\n",
        "    if pbn[i] == \" \":\n",
        "      suit += 13\n",
        "    elif pbn[i] == \".\":\n",
        "      suit += 13\n",
        "    elif pbn[i] == \"A\":\n",
        "      deal[suit] = 1\n",
        "    elif pbn[i] == \"K\":\n",
        "      deal[suit + 12] = 1\n",
        "    elif pbn[i] == \"Q\":\n",
        "      deal[suit + 11] = 1\n",
        "    elif pbn[i] == \"J\":\n",
        "      deal[suit + 10] = 1\n",
        "    elif pbn[i] == \"T\":\n",
        "      deal[suit + 9] = 1\n",
        "    else:\n",
        "      deal[suit + int(pbn[i]) - 1] = 1\n",
        "  return deal\n",
        "\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive/original/train_deals.npy'):\n",
        "  print(\"files exist\")\n",
        "  print(\"load files\")\n",
        "  train_deals = jnp.array(np.load('/content/drive/MyDrive/original/train_deals.npy')[: config.TRAIN_SAMPLE_NUM, :], dtype=jnp.float32)\n",
        "  train_ddts = jnp.array(np.load('/content/drive/MyDrive/original/train_ddts.npy')[: config.TRAIN_SAMPLE_NUM, :], dtype=jnp.float32)\n",
        "  test_deals = jnp.array(np.load('/content/drive/MyDrive/original/test_deals.npy')[: config.TEST_SAMPLE_NUM, :], dtype=jnp.float32)\n",
        "  test_ddts = jnp.array(np.load('/content/drive/MyDrive/original/test_ddts.npy')[: config.TEST_SAMPLE_NUM, :], dtype=jnp.float32)\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"files don't exist\")\n",
        "  print(\"make files\")\n",
        "  dbname = \"/content/drive/MyDrive/original/dda.db\"\n",
        "  with sqlite3.connect(dbname) as conn:\n",
        "    df = pd.read_sql('select * from records', con=conn)\n",
        "  display(df)\n",
        "  train_deals = []\n",
        "  train_ddts = []\n",
        "  print(\"START : make train dataset\")\n",
        "  for i in tqdm.tqdm(range(config.TRAIN_SAMPLE_NUM)):\n",
        "    \n",
        "    content = json.loads(df.loc[i, \"CONTENT\"])\n",
        "    train_deals.append(pbn_to_bool(content[\"pbn\"]))\n",
        "    train_ddts.append(content[\"ddt\"])\n",
        "\n",
        "    \n",
        "  test_deals = []\n",
        "  test_ddts = []   \n",
        "  print(\"START : make test dataset\")\n",
        "  for i in tqdm.tqdm(range(config.TRAIN_SAMPLE_NUM, config.TRAIN_SAMPLE_NUM + config.TEST_SAMPLE_NUM)):\n",
        "    content = json.loads(df.loc[i, \"CONTENT\"])\n",
        "    test_deals.append(pbn_to_bool(content[\"pbn\"]))\n",
        "    test_ddts.append(content[\"ddt\"])\n",
        "\n",
        "  train_deals = np.array(train_deals)\n",
        "  train_ddts = np.array(train_ddts)\n",
        "  test_deals = np.array(test_deals)\n",
        "  test_ddts = np.array(test_ddts)\n",
        "  np.save('/content/drive/MyDrive/original/train_deals.npy', train_deals)\n",
        "  np.save('/content/drive/MyDrive/original/train_ddts.npy', train_ddts)\n",
        "  np.save('/content/drive/MyDrive/original/test_deals.npy', test_deals)\n",
        "  np.save('/content/drive/MyDrive/original/test_ddts.npy', test_ddts)\n",
        "  train_deals = jnp.array(train_deals, dtype=jnp.float32)\n",
        "  train_ddts = jnp.array(train_ddts, dtype=jnp.float32)\n",
        "  test_deals = jnp.array(test_deals, dtype=jnp.float32)\n",
        "  test_ddts = jnp.array(test_ddts, dtype=jnp.float32)\n",
        "print(jnp.shape(train_deals))\n",
        "print(jnp.shape(train_ddts))\n",
        "print(jnp.shape(test_deals))\n",
        "print(jnp.shape(test_ddts))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m8_bg3GjUo7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0cd2f1-a871-4811-cc36-cc17d017552c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0]\n",
            "7\n",
            "[208, 1024, 1024, 1024, 1024, 1024]\n",
            "[1024, 1024, 1024, 1024, 1024, 20]\n",
            "[[2716826189 1180506676]\n",
            " [4247964747 2620019508]\n",
            " [4167348494   78606281]\n",
            " [2231548119  292468403]\n",
            " [1537975273  917206909]\n",
            " [3902452147 3915755166]\n",
            " [3865067960 3800283793]]\n",
            "(6, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        }
      ],
      "source": [
        "# ヘルパー関数\n",
        "# dense NNのパラメータをランダム値で初期化\n",
        "def random_layer_params(m, n, key, scale=1e-2):\n",
        "  w_key, b_key = random.split(key)\n",
        "  return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n, ))\n",
        "\n",
        "# \"sizes\"をサイズにもつ全結合層の全ての層を初期化\n",
        "def init_network_params(sizes, key):\n",
        "  keys = random.split(key, len(sizes))\n",
        "  print(len(sizes))\n",
        "  print(sizes[:-1])\n",
        "  print(sizes[1:])\n",
        "  print(keys)\n",
        "  return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1: ], keys)]\n",
        "\n",
        "\n",
        "layer_sizes = [208]\n",
        "for i in range(config.LAYER_NUM):\n",
        "  layer_sizes.append(config.HIDDEN_LAYER_SIZE)\n",
        "layer_sizes.append(20)\n",
        "step_size = 0.01\n",
        "print(random.PRNGKey(0))\n",
        "params = init_network_params(layer_sizes, random.PRNGKey(0))\n",
        "print(jnp.shape(params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2HERkP-iXdFs"
      },
      "outputs": [],
      "source": [
        "from jax.scipy.special import logsumexp\n",
        "def relu(x):\n",
        "  return jnp.maximum(0, x)\n",
        "\n",
        "def predict(params, deal):\n",
        "  # 一個ごとの予測\n",
        "  activations = deal\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = jnp.dot(w, activations) + b\n",
        "    activations = relu(outputs)\n",
        "  \n",
        "  final_w, final_b = params[-1]\n",
        "  logits = jnp.dot(final_w, activations) + final_b\n",
        "  return logits \n",
        "\n",
        "# Make a batched version of the `predict` function\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FXfDfJmz-0dT"
      },
      "outputs": [],
      "source": [
        "import optax\n",
        "\n",
        "\n",
        "optimizer = optax.adam(config.lr)\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0Zu5za88_M_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714ffb7e-bb0e-47e0-ffef-1800d7a4724f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0119688\n"
          ]
        }
      ],
      "source": [
        "def loss(params, deals, ddts):\n",
        "  preds = batched_predict(params, deals)\n",
        "  return jnp.mean((ddts - preds) ** 2)\n",
        "\n",
        "def accuracy(params, deals, ddts):\n",
        "  predict_round = jnp.round(batched_predict(params, deals))\n",
        "  return jnp.count_nonzero(jnp.isclose(predict_round, ddts))/jnp.size(ddts)\n",
        "\n",
        "\"\"\"\n",
        "@jit\n",
        "def update(params, deals, ddts):\n",
        "  grads = grad(loss)(params, deals, ddts)\n",
        "  updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  return optax.apply_updates(params, updates)\n",
        "\"\"\"\n",
        "print(accuracy(params, test_deals, test_ddts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrHEOqk5AX04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc1ed4e-9f35-4b94-cbae-e58b67cacee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START learning\n"
          ]
        }
      ],
      "source": [
        "key = random.PRNGKey(0)\n",
        "keys = random.split(key, config.EPOCHS)\n",
        "print(\"START learning\")\n",
        "\n",
        "n_steps_per_epoch = math.ceil(config.TRAIN_SAMPLE_NUM / config.BATCH_SIZE)\n",
        "for epoch in range(config.EPOCHS):\n",
        "  start_time = time.time()\n",
        "  train_ddts = random.permutation(keys[epoch], train_ddts)\n",
        "  train_deals = random.permutation(keys[epoch], train_deals)\n",
        "  train_loss_sum = 0\n",
        "  for step in range(0, n_steps_per_epoch):\n",
        "    batched_train_deals = train_deals[step * config.BATCH_SIZE: (step + 1) * config.BATCH_SIZE]\n",
        "    batched_train_ddts = train_ddts[step * config.BATCH_SIZE: (step + 1) * config.BATCH_SIZE]\n",
        "    train_loss = loss(params, batched_train_deals, batched_train_ddts)\n",
        "    train_loss_sum += train_loss\n",
        "    grads = grad(loss)(params, batched_train_deals, batched_train_ddts)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params =  optax.apply_updates(params, updates)\n",
        "    metrics = {\"train/train_loss\": train_loss,\n",
        "               \"train/epoch\": (step + 1 + n_steps_per_epoch * epoch) / n_steps_per_epoch}\n",
        "    if step + 1 < n_steps_per_epoch:\n",
        "      wandb.log(metrics)\n",
        "  epoch_time = time.time() - start_time\n",
        "  test_loss = loss(params, test_deals, test_ddts)\n",
        "  test_accuracy = accuracy(params, test_deals, test_ddts)\n",
        "  test_metrics = {\"test/test_loss\": test_loss,\n",
        "                  \"test/test_accuracy\": test_accuracy}\n",
        "  wandb.log({**metrics, **test_metrics})\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set loss {}\".format(train_loss_sum / (n_steps_per_epoch)))\n",
        "  print(\"Test set loss {}\".format(test_loss))\n",
        "  print(\"Test set accuracy {}\".format(accuracy(params, test_deals, test_ddts)))\n",
        "\n",
        "wandb.finish()\n",
        "for i in range(10):\n",
        "  print(\"ddt:\")\n",
        "  print(test_ddts[i])\n",
        "  print(\"predict:\")\n",
        "  print(jnp.round(predict(params, test_deals[i])))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ1HeNBRUNrVJ0hZREUVaM",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}